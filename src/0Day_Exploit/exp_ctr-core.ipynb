{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "from scipy.stats import norm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Default Weight Variable\n",
    "This is used to try out different default variables for edges that are supposed to be trivial to traverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note this difference:\n",
    "Adding virtual start node: We ADD a new virtual starting node and connect it to existing root (starting nodes)\n",
    "Adding virtual target node: we REMOVE the old target nodes and replace them with one joint virtual target node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Virtual starting node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_add_entry_node(graph):\n",
    "    # First identify the original root nodes\n",
    "    original_roots = [n for n, deg in graph.in_degree() if deg == 0]\n",
    "    \n",
    "    if len(original_roots) > 1:\n",
    "        # add virtual entry node\n",
    "        entry = 0  # virtual entry node\n",
    "        graph.add_node(entry)\n",
    "        for r in original_roots:\n",
    "            graph.add_edge(entry, r, weight=DEFAULT_WEIGHT_VALUE)\n",
    "        return entry, graph, original_roots\n",
    "    else:\n",
    "        # Only one root, use it as entry\n",
    "        entry = original_roots[0]\n",
    "        return entry, graph, original_roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Virtual Target Node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_targets_with_multi_edges(orig_graph):\n",
    "    ## Part 1: Here we create a list of target nodes\n",
    "    targets = []\n",
    "    \n",
    "    # Iterate through all nodes and their out degrees\n",
    "    for node, out_degree in orig_graph.out_degree():\n",
    "        # If node has no outgoing edges it's obv. a target\n",
    "        if out_degree == 0:\n",
    "            targets.append(node)\n",
    "    \n",
    "    ## Part 2: We check that returns the original graph if there are no targets\n",
    "    if len(targets) <= 1:\n",
    "        return orig_graph\n",
    "\n",
    "    # Create just a merged label for the new virtual target node\n",
    "    merged_label = \"c(\" + \",\".join(str(t) for t in targets) + \")\"\n",
    "\n",
    "\n",
    "    ## Next we create new MultiDiGraph without edge weights for now\n",
    "    \n",
    "    ## Part 3: This part creates a new graph that replaces the original target nodes \n",
    "    # with the goal to create the new, merged virtual target node\n",
    "    # Immportant: This part does NOT yet add the specific edge weights from the CVSS data\n",
    "\n",
    "    # let start by creating new graph\n",
    "    newG = nx.MultiDiGraph()\n",
    "\n",
    "    # create list that contains all the non-target nodes\n",
    "    non_targets = []\n",
    "    for node in orig_graph.nodes():\n",
    "        if node not in targets:\n",
    "            non_targets.append(node)\n",
    "            \n",
    "    # Add all non-target nodes to new graph\n",
    "    for node in non_targets:\n",
    "        newG.add_node(node)\n",
    "        \n",
    "    # Add the virtual target node\n",
    "    newG.add_node(merged_label)\n",
    "    \n",
    "    ## Part 4: Edge Recreation between source nodes and the new Virtual Target Node\n",
    "    # This entire section ensures we add the CVSS data \n",
    "    # AND maintain all parallel edges and their weights just like R does to avoid confusion\n",
    "\n",
    "    # Track edges \n",
    "    pred_target_edges = {}\n",
    "\n",
    "    ## Part 4a: Collect ALL Edges going to Original Target Nodes\n",
    "\n",
    "    # We need this info to recreate these edges later with the virtual target node\n",
    "    # Example of what we're building:\n",
    "    # If node 5 has these edges:\n",
    "    # - Edge to node 15 with weight 0.3\n",
    "    # - Another edge to node 15 with weight 0.7\n",
    "    # - Edge to node 16 with weight 0.3\n",
    "    # Then pred_target_edges[5] will contain: [(0.3, '15'), (0.7, '15'), (0.3, '16')]\n",
    "    for u, v, data in orig_graph.edges(data=True):\n",
    "        if v in targets:\n",
    "            if u not in pred_target_edges:\n",
    "                pred_target_edges[u] = []\n",
    "            # in case there is no value we are adding the default weight value \n",
    "            weight = data.get('weight', DEFAULT_WEIGHT_VALUE)\n",
    "            pred_target_edges[u].append((weight, v))\n",
    "\n",
    "    ## Part 4b: Count How Many Times Each Weight Appears for Each Source Node\n",
    "\n",
    "    # For each source node, we count duplicate weights\n",
    "    # Example: If node 5 has three edges with weights [0.3, 0.7, 0.3]\n",
    "    # Then weight_counts will be {0.3: 2, 0.7: 1}\n",
    "    for u, edges in pred_target_edges.items():\n",
    "        weight_counts = {}\n",
    "        for weight, _ in edges:\n",
    "            weight_counts[weight] = weight_counts.get(weight, 0) + 1\n",
    "\n",
    "        ## Part 4c: Finally, create the actual edges to our virtual target\n",
    "        \n",
    "        # If weight_counts shows {0.3: 2, 0.7: 1}, we create:\n",
    "        # - 2 parallel edges with weight 0.3\n",
    "        # - 1 edge with weight 0.7\n",
    "        for weight, count in weight_counts.items():\n",
    "            for _ in range(count):\n",
    "                newG.add_edge(u, merged_label, weight=weight)\n",
    "    \n",
    "    ## Part 5: Copy Over All Other Edges That Don't Touch Target Nodes\n",
    "\n",
    "    for u, v, data in orig_graph.edges(data=True):\n",
    "        # Skip all edges that touch the targets\n",
    "        if v not in targets and u not in targets:\n",
    "            # data is used to unpacks all attributes automatically\n",
    "            # So if our edge had data = {'weight': 0.5, 'color': 'red'}\n",
    "            # This line becomes: newG.add_edge(u, v, weight=0.5, color='red')\n",
    "            newG.add_edge(u, v, **data)\n",
    "\n",
    "    return newG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements preparation for the Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_game_elements(graph, entry_node, original_roots):\n",
    "    \"\"\"\n",
    "    So this function is going to prepare all the elements we will need later for our analysis\n",
    "    Here we determine only the possible paths through the graph but don't care about the actual weights \n",
    "    and parallel edges, that will come later.\n",
    "\n",
    "    Returns:\n",
    "    routes: List of all possible paths from entry to target (ignoring parallel edges)\n",
    "    V: List of all nodes that appear in any route\n",
    "    as1: List of potential spot check locations for defender\n",
    "    as2: All possible attack paths for attacker \n",
    "    target_list: List containing our virtual target node\n",
    "    node_order: Nodes in V but sorted in topological order \n",
    "    adv_list: List of potential avatar locations\n",
    "    theta: weight of avatars starting at each node (set all to equal for now)\n",
    "    m: Number of different attack paths\n",
    "    \"\"\"\n",
    "    ## Part 1: Find our Target Node and lets make sure it is only one !\n",
    "    target_list = [n for n,d in graph.out_degree() if d == 0]\n",
    "    if len(target_list) != 1:\n",
    "        print(\"WARNING: Expected exactly one target node after contraction. Found:\", target_list)\n",
    "    \n",
    "    ## Part 2: Get all UNIQUE Possible Attack Routes Through Graph\n",
    "    # This means finding all possible node sequences like [0->1->2->target]\n",
    "\n",
    "    ## Part 2a: Let's get initial Raw Path List, including duplicates from parallel edges\n",
    "    # Example: If we have two edges between 1->2, we could get for example:\n",
    "    #   Path1: [0->1->2->target] (using first 1->2 edge)\n",
    "    #   Path2: [0->1->2->target] (using second 1->2 edge)\n",
    "    raw_routes = list(nx.all_simple_paths(graph, entry_node, target_list[0]))\n",
    "\n",
    "    ## Part 2b: Remove Duplicate Paths\n",
    "    consolidated_routes = []\n",
    "    seen_paths = set()\n",
    "\n",
    "    for path in raw_routes:\n",
    "        path_key = tuple(path)\n",
    "        if path_key not in seen_paths:\n",
    "            seen_paths.add(path_key)\n",
    "            consolidated_routes.append(list(path))\n",
    "\n",
    "    # routes now contains our final list of unique possible attack paths\n",
    "    routes = consolidated_routes\n",
    "\n",
    "    ## Part 3: Create Node Sets We Need for the Game\n",
    "    # Part 3a: First let's get all unique nodes (V) that appear in any route\n",
    "    V = sorted(set(node for path in routes for node in path), key=str)\n",
    "\n",
    "    # Part 3b: Make sure nodes are in proper order \n",
    "    topo_all = list(nx.topological_sort(graph))\n",
    "    node_order = []\n",
    "    for n in topo_all:\n",
    "        if n in V:\n",
    "            node_order.append(n)\n",
    "    \n",
    "    ## Part 4: Create the  Special Node Lists \n",
    "    # Part 4a: Create as1, we exclude virtual starting node, original roots and virtual target node\n",
    "    excluded = {entry_node} | set(target_list) | set(original_roots)\n",
    "\n",
    "    as1 = []\n",
    "    for n in V:\n",
    "        if n not in excluded:\n",
    "            as1.append(n)\n",
    "\n",
    "    # Part 4b: Set up attack paths (as2)\n",
    "    as2 = routes\n",
    "\n",
    "    ## Part 5: Set up Game Parameters\n",
    "    # First all potential avatar locations\n",
    "    adv_list = []\n",
    "    excluded_nodes = set([entry_node]) | set(target_list)\n",
    "    for n in V:\n",
    "        if n not in excluded_nodes:\n",
    "            adv_list.append(n)\n",
    "    \n",
    "    if len(adv_list) == 0:\n",
    "        print(\"WARNING: No adversary intermediate locations found. Check graph structure.\")\n",
    "\n",
    "    # Part 5b: Calculate initial probabilities for each possible attacker location\n",
    "    theta = {loc: 1/len(adv_list) for loc in adv_list} if adv_list else {}\n",
    "    \n",
    "    # Part 5c: Count total number of attack paths\n",
    "    m = len(routes)\n",
    "    \n",
    "    return routes, V, as1, as2, target_list, node_order, adv_list, theta, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Payoffs based on the game elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method necessary to calculate Pay offs within"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is mostly useless and can be removed long term. In my current implementation all we care about is the last entry of U = [0.17, 0.10, 0.63, 0.10, 1e-7] which represents the prob. of the attacker to reach the target node.\n",
    "\n",
    "And per one U (Node Check & Attack Path pair), we extract only this one value for the final pay off matrix. \n",
    "lossDistribution() does not add anything of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The current version is completely useless. \n",
    "# I wrote it here because the R version had it, but as of now it does not do anything\n",
    "# What we need is just the last entry of U\n",
    "# But this method does not change U in any way\n",
    "# might be usefule some day for some added complexity ? Leaving it in for now...\n",
    "def lossDistribution(U):\n",
    "    \"\"\"\n",
    "    Creates standardized format matching R's lossDistribution output.\n",
    "    U is already normalized and has no zeros due to preprocessing.\n",
    "    Only U[-1] (last entry of dpdf) is actually used in solve_game.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'dpdf': U,  \n",
    "        'support': np.arange(1, len(U) + 1),\n",
    "        'cdf': np.cumsum(U),\n",
    "        'tail': 1 - np.cumsum(U) + U,\n",
    "        'range': [1, len(U)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Payoffs for each path/check pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_payoff_distribution(graph, as1, as2, V, adv_list, theta, random_steps_fn, \n",
    "                                 attack_rate, defense_rate, node_order):\n",
    "   \"\"\"\n",
    "   For each (node check & attack path combination) this method calculates the probabilities of \n",
    "   the avatars reaching each individual node along the attack path\n",
    "   \n",
    "   It then aggregates these results in one final U vector, where the last entry contains the \n",
    "   aggregate information of any of these avatars reaching the target node.\n",
    "\n",
    "   If defender performs node check on any node that lies within the chosen attack path, this obv. \n",
    "   will affect the probabilities, bouncing the avatars back to the last pre-check location\n",
    "\n",
    "   If edge weights are present they will affect movement probabilities through the random_steps_fn\n",
    "   \n",
    "\n",
    "   Returns:\n",
    "   payoffs: List of probability distributions, one for each (node check location & attack path) pair\n",
    "   \"\"\"\n",
    "   payoffs = []\n",
    "\n",
    "   ## Part 1: Process Each Defender Check + Attack Path Combination\n",
    "\n",
    "   # For each pair, we calculate:\n",
    "   # 1. Where avatar starting from different positions might end up\n",
    "   # 2. How the defender's check point affects these probabilities\n",
    "   # 3. A final combined probability distribution across all nodes on (potentially truncated) attack path U\n",
    "   for check in as1:\n",
    "       for path in as2:\n",
    "           U = np.zeros(len(V))\n",
    "\n",
    "           # print(f\"\\n++++++++++++++++++++++++++++++++\")\n",
    "           # print(f\"attack_rate = {attack_rate}, defense_rate = {defense_rate}\")\n",
    "           # print(f\"--- Starting payoff calc for check = {check}, path = {path} ---\\n\")\n",
    "\n",
    "           ## Part 2: Handle each avatar\n",
    "\n",
    "           # 1. Create temporary vector L to hold the probabilities for each avatar\n",
    "           # 2. Calculate probabilities differently if avatar is on/off attack path\n",
    "           # 3. Weight probability of attacker starting at this position (theta)\n",
    "           # 4. Add weighted probabilities to final vector U\n",
    "           for avatar in adv_list:\n",
    "               L = np.zeros(len(V))\n",
    "\n",
    "               ## Part 2a: Calculate Probabilities When avatar location is on Path\n",
    "\n",
    "               if avatar in path:\n",
    "                   # Extract path that starts with the location of the avatar on the path\n",
    "                   start_idx = path.index(avatar)\n",
    "                   route = path[start_idx:]\n",
    "                   #print(f\"\\nProcessing avatar {avatar}:\")\n",
    "                   #print(f\"Route from avatar: {route}\")\n",
    "                   \n",
    "                   # Get raw probabilities\n",
    "                   pdf_d = random_steps_fn(route, attack_rate, defense_rate, graph)\n",
    "                   #print(f\"PDF for entire route: {pdf_d}\")\n",
    "\n",
    "                   ## Part 2b: Adjust Probabilities Based on Defender's Check Point\n",
    "                   # If the defender spot checks on this path:\n",
    "                   # 1. Truncate probabilities at check point (avatar can not progress past it)\n",
    "                   # 2. Renormalize \n",
    "                   if check in route:\n",
    "                       check_idx = route.index(check)\n",
    "                       # Add 1 to include the check point itself\n",
    "                       cutPoint = check_idx + 1\n",
    "                   else:\n",
    "                       cutPoint = len(route)\n",
    "                   #print(f\"Cut point: {cutPoint}\")\n",
    "\n",
    "                   # Take probabilities up to check point and renormalize\n",
    "                   # Case 1: If probabilities are basically zero \n",
    "                   # This means attacker is guaranteed will reach last node in path\n",
    "                   pdf_subset = pdf_d[:cutPoint]\n",
    "                   if np.sum(pdf_subset) < 1e-15:\n",
    "                       payoffDistr = np.zeros(cutPoint)\n",
    "                       payoffDistr[-1] = 1.0\n",
    "                   # Case 2: Normal case with non-zero probabilities\n",
    "                   #   - Normalize probabilities to sum to 1.0\n",
    "                   #   - Example: if pdf_subset=[0.2, 0.3] -> payoffDistr=[0.4, 0.6]\n",
    "                   else:\n",
    "                       payoffDistr = pdf_subset / np.sum(pdf_subset)\n",
    "                   \n",
    "                   #print(f\"PDF subset: {pdf_subset}\")\n",
    "                   #print(f\"Payoff distribution: {payoffDistr}\")\n",
    "\n",
    "                   # Map probabilities to the truncated path\n",
    "                   route_subset = route[:cutPoint]\n",
    "                   #print(f\"Route subset: {route_subset}\")\n",
    "                   # for idx_node, node in enumerate(route_subset):\n",
    "                   #     L[V.index(node)] = pdf_d[idx_node]\n",
    "\n",
    "                   for idx_node, node in enumerate(route_subset):\n",
    "                       L[V.index(node)] = payoffDistr[idx_node]\n",
    "                   \n",
    "                   # print(\"L distribution for this avatar (BEFORE weighting by Theta):\")\n",
    "                   # for idx_l, val in enumerate(L):\n",
    "                   #     if val > 1e-10:\n",
    "                   #         print(f\"  Node {V[idx_l]} : {val}\")\n",
    "\n",
    "               ## Part 2c: Handle Case Where avatar is not on the chosen attack path\n",
    "               # If avatar not on path just set probability to 1, they are staying where they are\n",
    "               else:\n",
    "                   L[V.index(avatar)] = 1.0\n",
    "                   # print(f\"\\nProcessing avatar {avatar} (not in path):\")\n",
    "                   # print(f\"L[{avatar}] = 1.0\")\n",
    "\n",
    "               ## Part 2d: Add Weighted Contribution to Final Probabilities\n",
    "               \n",
    "               # Weight this starting position's probabilities by theta\n",
    "               # aggregate all the L vectors into one final U vector\n",
    "               #print(f\"\\nTheta[{avatar}] = {theta[avatar]}\")\n",
    "               U += theta[avatar] * L\n",
    "               #print(\"Current U after adding this avatar's contribution:\")\n",
    "               # for idx_u, val in enumerate(U):\n",
    "               #     if val > 1e-10:\n",
    "               #         print(f\"  Node {V[idx_u]} : {val}\")\n",
    "\n",
    "\n",
    "           # print(f\"\\n--- Aggregated U for check={check}, path={path} (BEFORE normalization) ---\")\n",
    "           # for idx_u, val in enumerate(U):\n",
    "           #     if val > 1e-10:\n",
    "           #         print(f\"  Node {V[idx_u]} : {val}\")\n",
    "           \n",
    "           ## Part 3: Clean Up \n",
    "\n",
    "           # Part 3a: Normalize and Handle Edge Cases \n",
    "           # Make sure that no zero probabilities and normalize to sum to 1\n",
    "           U_sum = np.sum(U)\n",
    "           if U_sum < 1e-15:\n",
    "               U = np.full_like(U, 1e-7)\n",
    "           else:\n",
    "               # normalize and prevent 0 probabilities\n",
    "               U = U/U_sum\n",
    "               U = np.where(U < 1e-7, 1e-7, U)\n",
    "           \n",
    "           # Part 3b: Reorder according to topological order\n",
    "           node_positions = [V.index(n) for n in node_order]\n",
    "           U = U[node_positions]\n",
    "\n",
    "           # print(f\"\\n--- Normalized U for check={check}, path={path} ---\")\n",
    "           # for idx_u2, val2 in enumerate(U):\n",
    "           #     if val2 > 1e-10:\n",
    "           #         print(f\"  Node {node_order[idx_u2]} : {val2}\")\n",
    "\n",
    "           # other debug stuff\n",
    "           # ld = {\n",
    "           #     'dpdf': U,\n",
    "           #     'support': range(1, len(U) + 1),\n",
    "           #     'cdf': np.cumsum(U),\n",
    "           #     'tail': 1 - np.cumsum(U) + U\n",
    "           # }\n",
    "\n",
    "           ## Part 4: Create Smoothed Distribution\n",
    "           # but effectively this does nothing but could be used to add complexity later\n",
    "           ld = lossDistribution(U)\n",
    "           payoffs.append(ld)\n",
    "\n",
    "   return payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_game(payoffs, as1, as2):\n",
    "    n = len(as1)\n",
    "    m = len(as2)\n",
    "\n",
    "    # print(\"\\n=== Debug: Strategy Mappings ===\")\n",
    "    # print(\"Defender strategies (as1):\", as1)\n",
    "    # print(\"Attacker paths (as2):\")\n",
    "    # for idx, path in enumerate(as2):\n",
    "    #     print(f\"Path {idx}:\", path)\n",
    "    \n",
    "    # Create payoff matrix\n",
    "    payoff_matrix = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            idx = i*m + j\n",
    "            ld = payoffs[idx]\n",
    "            payoff_matrix[i, j] = ld['dpdf'][-1]\n",
    "            #print(f\"Which finally leads to the following entry in the payoff matrix: {payoff_matrix[i, j]}\")\n",
    "\n",
    "\n",
    "    # NEW DEBUG CODE which i use to Print payoff matrix before optimization\n",
    "    if debug_mode:\n",
    "        print(\"\\n=== Debug: Final Payoff Matrix ===\")\n",
    "        print(f\"Matrix dimensions: {n} x {m}\\n\")\n",
    "        print(\"Payoff Matrix (probability of reaching target):\")\n",
    "        for i in range(n):\n",
    "            row_str = f\"Row {i+1:2d}:\"\n",
    "            for j in range(m):\n",
    "                row_str += f\" {payoff_matrix[i,j]:8.6f}\"\n",
    "            print(row_str)\n",
    "        print(\"\\n=== End Debug: Final Payoff Matrix ===\\n\")\n",
    "    \n",
    "    ### Start Defender's optimization ###\n",
    "    c = np.zeros(n+1)\n",
    "    c[0] = 1.0\n",
    "    \n",
    "    A_ub = np.zeros((m, n+1))\n",
    "    b_ub = np.zeros(m)\n",
    "    for j in range(m):\n",
    "        A_ub[j,0] = -1.0\n",
    "        for i in range(n):\n",
    "            A_ub[j,i+1] = payoff_matrix[i,j]\n",
    "            \n",
    "    A_eq = np.zeros((1, n+1))\n",
    "    A_eq[0,1:] = 1.0\n",
    "    b_eq = np.array([1.0])\n",
    "    \n",
    "    bounds = [(0,None)]*(n+1)\n",
    "    \n",
    "    v_defender = None\n",
    "    v_attacker = None\n",
    "    \n",
    "    # Solve the Linear Programming for defender's strategy\n",
    "    res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)\n",
    "    \n",
    "    ### End Defender's optimization ###\n",
    "\n",
    "    if res.success:\n",
    "        # Extract the results for later logging\n",
    "        v_defender = res.x[0]\n",
    "        x_def = res.x[1:]\n",
    "        \n",
    "        ### Start Attacker's optimization ###\n",
    "        c_att = np.zeros(m+1)\n",
    "        c_att[0] = -1.0\n",
    "        \n",
    "        A_ub_att = np.zeros((n, m+1))\n",
    "        b_ub_att = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            A_ub_att[i,0] = 1.0\n",
    "            for j in range(m):\n",
    "                A_ub_att[i,j+1] = -payoff_matrix[i,j]\n",
    "                \n",
    "        A_eq_att = np.zeros((1, m+1))\n",
    "        A_eq_att[0,1:] = 1.0\n",
    "        b_eq_att = np.array([1.0])\n",
    "        \n",
    "        bounds_att = [(0,None)]*(m+1)\n",
    "\n",
    "        # solve the LP for attacker's strategy\n",
    "        res_att = linprog(c_att, A_ub=A_ub_att, b_ub=b_ub_att, \n",
    "                         A_eq=A_eq_att, b_eq=b_eq_att, bounds=bounds_att)\n",
    "        \n",
    "        ### End Attacker's optimization ###\n",
    "        \n",
    "        if res_att.success:\n",
    "            # Extract attacker results for later logging\n",
    "            y_att = res_att.x[1:]\n",
    "            v_attacker = res_att.x[0]   # new; remove the negative sign because c_att[0] = -1.0\n",
    "            \n",
    "            # Now both values are defined, we can check\n",
    "            if abs(v_defender - v_attacker) > 1e-5:\n",
    "                logger.info(\"\\nWarning: Defender and attacker values don't match!\")\n",
    "                logger.info(f\"Defender value: {v_defender:.6f}\")\n",
    "                logger.info(f\"Attacker value: {v_attacker:.6f}\")\n",
    "            \n",
    "            return {\n",
    "                'optimal_defense': dict(zip(as1, x_def)),\n",
    "                'attacker_strategy': y_att,\n",
    "                'defender_success': v_defender,\n",
    "                'attacker_success': v_attacker\n",
    "            }\n",
    "    \n",
    "    logger.info(\"LP optimization failed\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Code (Can be deleted sooner or later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_debug_info(graph, stage=\"\"):\n",
    "    print(f\"\\n{stage}:\")\n",
    "    print(\"Nodes:\", list(graph.nodes()))\n",
    "    print(\"Total list of Edges with their weights:\")\n",
    "    if isinstance(graph, nx.MultiDiGraph):\n",
    "        # For MultiDiGraph, we need to handle multiple edges between same nodes\n",
    "        for u, v, key, data in graph.edges(data=True, keys=True):\n",
    "            weight = data.get('weight', DEFAULT_WEIGHT_VALUE)  \n",
    "            print(f\"{u} -> {v} (key={key}) : {weight}\")\n",
    "    else:\n",
    "        # Original printing for regular DiGraph\n",
    "        for u, v, data in graph.edges(data=True):\n",
    "            weight = data.get('weight', DEFAULT_WEIGHT_VALUE)  \n",
    "            print(f\"{u} -> {v} : {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute force re-ordering method for Experiment 3 & 4 for easier debugging. \n",
    "Useless for other Experiments (can be removed or ignored later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_strategies(as1, as2):\n",
    "    # R's order: [5, 15, 6, 8, 10, 7, 11, 9]\n",
    "    r_order = [5, 15, 6, 8, 10, 7, 11, 9]\n",
    "    \n",
    "    # Print desired order information\n",
    "    print(\"\\nDebug - Reordering process:\")\n",
    "    print(\"Desired order:\", r_order)\n",
    "    \n",
    "    # Create new ordered list\n",
    "    as1_reordered = []\n",
    "    for node in r_order:\n",
    "        if node in as1:\n",
    "            as1_reordered.append(node)\n",
    "    \n",
    "    # Reorder paths according to R's path ordering\n",
    "    r_paths = [\n",
    "        [0, 1, 5, 15, 'c(12,13,14,16)'],\n",
    "        [0, 3, 6, 8, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 3, 6, 8, 'c(12,13,14,16)'],\n",
    "        [0, 3, 8, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 3, 8, 'c(12,13,14,16)'],\n",
    "        [0, 4, 7, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 4, 7, 'c(12,13,14,16)'],\n",
    "        [0, 2, 11, 'c(12,13,14,16)'],\n",
    "        [0, 2, 9, 'c(12,13,14,16)'],\n",
    "        [0, 2, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 2, 'c(12,13,14,16)']\n",
    "    ]\n",
    "    \n",
    "    # Create new ordered list of paths\n",
    "    as2_reordered = []\n",
    "    for r_path in r_paths:\n",
    "        for path in as2:\n",
    "            if path == r_path:\n",
    "                as2_reordered.append(path)\n",
    "                break\n",
    "    \n",
    "    return as1_reordered, as2_reordered\n",
    "\n",
    "def debug_paths(as1, as2):\n",
    "    # Print debug information for strategies\n",
    "    print(\"\\nDebug - Current defender Node Check locations:\")\n",
    "    print(\"as1:\", as1)\n",
    "    \n",
    "    # Print debug information for paths\n",
    "    print(\"\\nDebug - Current Attack paths:\")\n",
    "    for i, path in enumerate(as2):\n",
    "        print(f\"  {i}: {path}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to run the Actual Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(attacker_graph, defender_graph=None, attack_rate_list=None, dropped=None, defense_rate_list=None, random_steps_fn=None):\n",
    "\n",
    "    if defender_graph is None:\n",
    "        defender_graph = attacker_graph\n",
    "        \n",
    "    final_eq = None\n",
    "\n",
    "    ####### Graph pre processing for ATTACKER #######\n",
    "    if debug_mode:\n",
    "        print_debug_info(attacker_graph, \"This is the Attacker Graph\")\n",
    "\n",
    "    atk_virtual_entry_node, attacker_graph, atk_original_roots = find_and_add_entry_node(attacker_graph)\n",
    "    attacker_graph = merge_targets_with_multi_edges(attacker_graph) \n",
    "\n",
    "    if debug_mode:\n",
    "        print_debug_info(attacker_graph, \"After merging targets of attack graph\")\n",
    "\n",
    "\n",
    "    ####### Calculate ATTACKER elements #######\n",
    "    _, V, _, as2, target_list, node_order, adv_list, theta, m = generate_game_elements(\n",
    "        attacker_graph, atk_virtual_entry_node, atk_original_roots)\n",
    "\n",
    "    ####### Testing pre-processing for defender_graph #######\n",
    "    if debug_mode:\n",
    "        print_debug_info(defender_graph, \"This is the Defender Graph\")\n",
    "    def_virtual_entry_node, defender_graph, def_original_roots = find_and_add_entry_node(defender_graph)\n",
    "    defender_graph = merge_targets_with_multi_edges(defender_graph) \n",
    "\n",
    "    if debug_mode:\n",
    "        print_debug_info(defender_graph, \"After merging targets of the Defender Graph\")\n",
    "\n",
    "    ####### Calculate DEFENDER elements #######\n",
    "    _, _, as1, _, _, _, _, _, _ = generate_game_elements(defender_graph, def_virtual_entry_node, def_original_roots)\n",
    "\n",
    "    # Forceful reordering of strategies to be better able to debug \n",
    "    # Remove later used mainly for experiment 3\n",
    "    # as1, as2 = reorder_strategies(as1, as2)\n",
    "\n",
    "    # Always log attack paths to the .log file \n",
    "    logger.info(\"\\nDebug - Current Attack paths:\")\n",
    "    for i, path in enumerate(as2):\n",
    "        logger.info(f\"  {i}: {path}\")\n",
    "\n",
    "    # Some debugs\n",
    "    if debug_mode:\n",
    "        print(\"\\n Dropped nodes are: \", dropped)\n",
    "        debug_paths(as1, as2)\n",
    "\n",
    "\n",
    "    \n",
    "    if not defense_rate_list:\n",
    "        defense_rate_list = [0]\n",
    "    if not attack_rate_list:\n",
    "        attack_rate_list = [0]\n",
    "    \n",
    "    for defenseRate in defense_rate_list:\n",
    "        for attackRate in attack_rate_list:\n",
    "            logger.info(\"\\n++++++++++++++++++++++++++++++++\")\n",
    "            logger.info(f\"\\nThe virtual target nodeID is {target_list[0]}\\n\")\n",
    "            logger.info(f\"attack rate =  {attackRate} , defense rate =  {defenseRate} \\n\")\n",
    "            logger.info(\"\\tequilibrium for multiobjective security game (MOSG)\\n\")\n",
    "            \n",
    "\n",
    "            # changing this was important \n",
    "            payoffs = calculate_payoff_distribution(\n",
    "                attacker_graph, as1, as2, V, adv_list, theta, \n",
    "                random_steps_fn,  # Just pass the function directly\n",
    "                attackRate, defenseRate, node_order\n",
    "            )\n",
    "\n",
    "            # debug_payoff_matrix(payoffs, as1, as2)\n",
    "            \n",
    "            eq = solve_game(payoffs, as1, as2)\n",
    "            if eq is not None:\n",
    "                final_eq = eq  \n",
    "                logger.info(\"optimal defense strategy:\")\n",
    "                logger.info(\"         prob.\")\n",
    "                for node, prob in sorted(eq['optimal_defense'].items(), key=lambda x: str(x[0])):\n",
    "                    logger.info(f\"{node} {prob:.6e}\")\n",
    "                \n",
    "                logger.info(\"\\nworst case attack strategies per goal:\")\n",
    "                logger.info(\"          1\")\n",
    "                if 'attacker_strategy' in eq:\n",
    "                    for idx, prob in enumerate(eq['attacker_strategy'], 1):\n",
    "                        logger.info(f\"{idx} {prob:.7f}\")\n",
    "                logger.info(f\"[1] {eq['attacker_success']:.3f}\")\n",
    "                \n",
    "                logger.info(f\"\\nDefender can keep attacker success below: {eq['defender_success']:.3f}\")\n",
    "                logger.info(f\"Attacker can guarantee success probability of: {eq['attacker_success']:.3f}\")\n",
    "\n",
    "    return final_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to be called in different Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Make sure we're using the main logger\n",
    "    switch_logger(use_subgraph_logger=False)\n",
    "    \n",
    "    logger.info(\"\\n\\n\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"BASELINE RUN: BOTH ATTACKER AND DEFENDER HAVE FULL GRAPH KNOWLEDGE\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"\\n\")\n",
    "    \n",
    "    # Run the baseline\n",
    "    print(f\"We start with the baseline graph calculation!\")\n",
    "    baseline_result = run_game(attacker_graph=full_attack_graph, defender_graph=full_attack_graph, attack_rate_list=attack_rate_list, \n",
    "                              defense_rate_list=defense_rate_list, random_steps_fn=random_steps)\n",
    "    \n",
    "    # If toggle is False, also run subgraph analysisb for 0day exploits\n",
    "    print(f\"Now we are going to run the subgraph analysis\")\n",
    "    if not RUN_BASELINE_ONLY:\n",
    "        # Switch to subgraph logger\n",
    "        switch_logger(use_subgraph_logger=True)\n",
    "        \n",
    "        logger.info(\"\\n\")\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(f\"STARTING SUBGRAPH ANALYSIS WITH {len(defender_subgraphs_list)} DEFENDER SUBGRAPHS\")\n",
    "        logger.info(f\"Drop percentage is : {current_drop_percentage}\")\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"\\n\")\n",
    "        \n",
    "        # List to store attacker\n",
    "        attacker_success_values = []\n",
    "        # List to store defender\n",
    "        attacker_success_values = []\n",
    "\n",
    "        total_nodes_dropped_list = []\n",
    "        \n",
    "        # Run the subgraph analysis\n",
    "        for i in range(len(defender_subgraphs_list)):\n",
    "            defender_subgraph, dropped_nodes, cleaned_nodes = defender_subgraphs_list[i]\n",
    "\n",
    "            # Track total nodes dropped for this run for later calculations we will do\n",
    "            total_nodes_dropped = len(dropped_nodes) + len(cleaned_nodes)\n",
    "            total_nodes_dropped_list.append(total_nodes_dropped)\n",
    "\n",
    "            logger.info(\"\\n\")\n",
    "            logger.info(\"-\"*60)\n",
    "            logger.info(f\"SUBGRAPH RUN #{i+1}: DEFENDER HAS LIMITED NETWORK VISIBILITY\")\n",
    "            logger.info(f\"Drop percentage is: {current_drop_percentage}\")\n",
    "            logger.info(f\"Node(s) Nr. {', '.join(map(str, dropped_nodes))} were dropped from this graph\")\n",
    "            logger.info(f\"Additionally {len(cleaned_nodes)} nodes were cleaned afterwards\")\n",
    "            logger.info(f\"So in total {total_nodes_dropped} Nodes were dropped\")\n",
    "            logger.info(\"-\"*60)\n",
    "            logger.info(\"\\n\")\n",
    "\n",
    "            # Prepare the graph (deep copy only the subgraph part)\n",
    "            defender_subgraph_current = deepcopy(defender_subgraph)\n",
    "\n",
    "            result = run_game(attacker_graph=full_attack_graph, defender_graph=defender_subgraph_current, dropped = dropped_nodes,\n",
    "                            attack_rate_list=attack_rate_list, \n",
    "                            defense_rate_list=defense_rate_list, random_steps_fn=random_steps)\n",
    "            \n",
    "            if result and 'attacker_success' in result:\n",
    "                attacker_success_values.append(result['attacker_success'])\n",
    "\n",
    "        # Calculate and log the average\n",
    "        if attacker_success_values:\n",
    "            avg_attacker_success = sum(attacker_success_values) / len(attacker_success_values)\n",
    "            # Calculate average total nodes dropped\n",
    "            avg_total_nodes_dropped = sum(total_nodes_dropped_list) / len(total_nodes_dropped_list)\n",
    "\n",
    "            # Get total number of nodes in the full graph for our later calculations\n",
    "            total_nodes = full_attack_graph.number_of_nodes()\n",
    "\n",
    "            # Calculate percentages\n",
    "            initial_drop_percentage = (len(dropped_nodes) / total_nodes) * 100\n",
    "            total_drop_percentage = (avg_total_nodes_dropped / total_nodes) * 100\n",
    "\n",
    "            logger.info(\"\\n\\n\")\n",
    "            logger.info(\"=\"*80)\n",
    "            logger.info(\"SUBGRAPH ANALYSIS SUMMARY\")\n",
    "            logger.info(\"=\"*80)\n",
    "            logger.info(f\"Number of subgraphs analyzed: {len(attacker_success_values)}\")\n",
    "            logger.info(f\"Total number of nodes in the graph: {total_nodes}\")\n",
    "            logger.info(f\"Initial number of dropped nodes per subgraph: {len(dropped_nodes)}\")\n",
    "            logger.info(f\"% of dropped nodes (initially): {initial_drop_percentage:.1f}%\")\n",
    "            logger.info(f\"Average total nodes dropped (including cleanup): {avg_total_nodes_dropped:.2f}\")\n",
    "            logger.info(f\"% of total nodes dropped (including cleanup): {total_drop_percentage:.1f}%\")\n",
    "            logger.info(f\"Baseline attacker success: {baseline_result['attacker_success']:.3f}\")\n",
    "            logger.info(f\"Average attacker success across subgraphs: {avg_attacker_success:.3f}\")\n",
    "            logger.info(f\"Difference from baseline: {'+' if avg_attacker_success - baseline_result['attacker_success'] > 0 else ''}{avg_attacker_success - baseline_result['attacker_success']:.3f}\")\n",
    "            logger.info(\"=\"*80)\n",
    "            print(\"The subgraph analysis is done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

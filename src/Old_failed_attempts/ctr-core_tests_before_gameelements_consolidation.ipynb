{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "from scipy.stats import norm\n",
    "from copy import deepcopy\n",
    "# from math import factorial, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note this difference:\n",
    "Adding virtual start node: We ADD a new virtual starting node and connect it to existing root (starting nodes)\n",
    "Adding virtual target node: we REMOVE the old target nodes and replace them with one joint virtual target node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Virtual starting node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_add_entry_node(graph):\n",
    "    # First identify the original root nodes\n",
    "    original_roots = [n for n, deg in graph.in_degree() if deg == 0]\n",
    "    \n",
    "    if len(original_roots) > 1:\n",
    "        # add virtual entry node\n",
    "        entry = 0  # virtual entry node\n",
    "        graph.add_node(entry)\n",
    "        for r in original_roots:\n",
    "            graph.add_edge(entry, r, weight=1)\n",
    "        return entry, graph, original_roots\n",
    "    else:\n",
    "        # Only one root, use it as entry\n",
    "        entry = original_roots[0]\n",
    "        return entry, graph, original_roots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Virtual Target Node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_targets_with_multi_edges(orig_graph):\n",
    "    ## Part 1: This part is concerned only with creating a list of target nodes\n",
    "    targets = []\n",
    "    \n",
    "    # Iterate through all nodes and their out degrees\n",
    "    for node, out_degree in orig_graph.out_degree():\n",
    "        # If node has no outgoing edges (degree=0), it's a target\n",
    "        if out_degree == 0:\n",
    "            targets.append(node)\n",
    "    \n",
    "    ## Part 2: Simple check that just returns the original graph if there are no targets\n",
    "    if len(targets) <= 1:\n",
    "        return orig_graph\n",
    "\n",
    "    # Create just a merged label for the new virtual target node\n",
    "    merged_label = \"c(\" + \",\".join(str(t) for t in targets) + \")\"\n",
    "\n",
    "\n",
    "    ## Create new MultiDiGraph without edge weights for now\n",
    "    \n",
    "    ## Part 3: This part creates a new graph that replaces the original target nodes \n",
    "    # with the new virtual target node\n",
    "    # Immportant: This part does NOT yet add the specific edge weights between the nodes\n",
    "\n",
    "    # create list that contains all the non-target nodes\n",
    "    newG = nx.MultiDiGraph()\n",
    "\n",
    "    # create list that contains all the non-target nodes\n",
    "    non_targets = []\n",
    "    for node in orig_graph.nodes():\n",
    "        if node not in targets:\n",
    "            non_targets.append(node)\n",
    "            \n",
    "    # Add all non-target nodes to new graph\n",
    "    for node in non_targets:\n",
    "        newG.add_node(node)\n",
    "        \n",
    "    # Add the virtual target node\n",
    "    newG.add_node(merged_label)\n",
    "    \n",
    "    ## Part 4: Edge Recreation between source nodes and the new Virtual Target Node\n",
    "    # This entire section ensures we maintain all parallel edges and their weights just like R does\n",
    "\n",
    "    # Track edges \n",
    "    pred_target_edges = {}\n",
    "\n",
    "    ## Part 4a: Collect ALL Edges going to Original Target Nodes\n",
    "\n",
    "    # We need this info to recreate these edges later with the virtual target node\n",
    "    # Example of what we're building:\n",
    "    # If node 5 has these edges:\n",
    "    # - Edge to node 15 with weight 0.3\n",
    "    # - Another edge to node 15 with weight 0.7\n",
    "    # - Edge to node 16 with weight 0.3\n",
    "    # Then pred_target_edges[5] will contain: [(0.3, '15'), (0.7, '15'), (0.3, '16')]\n",
    "    for u, v, data in orig_graph.edges(data=True):\n",
    "        if v in targets:\n",
    "            if u not in pred_target_edges:\n",
    "                pred_target_edges[u] = []\n",
    "            weight = data.get('weight', 1)\n",
    "            pred_target_edges[u].append((weight, v))\n",
    "\n",
    "    ## Part 4b: Count How Many Times Each Weight Appears for Each Source Node\n",
    "\n",
    "    # For each source node, we count duplicate weights\n",
    "    # Example: If node 5 has three edges with weights [0.3, 0.7, 0.3]\n",
    "    # Then weight_counts will be {0.3: 2, 0.7: 1}\n",
    "    for u, edges in pred_target_edges.items():\n",
    "        weight_counts = {}\n",
    "        for weight, _ in edges:\n",
    "            weight_counts[weight] = weight_counts.get(weight, 0) + 1\n",
    "\n",
    "        ## Part 4c: For this one source node, finally, create the actual edges to our virtual target\n",
    "        \n",
    "        # If weight_counts shows {0.3: 2, 0.7: 1}, we create:\n",
    "        # - 2 parallel edges with weight 0.3\n",
    "        # - 1 edge with weight 0.7\n",
    "        for weight, count in weight_counts.items():\n",
    "            for _ in range(count):\n",
    "                newG.add_edge(u, merged_label, weight=weight)\n",
    "    \n",
    "\n",
    "    ## Part 5: Copy Over All Other Edges That Don't Touch Target Nodes\n",
    "\n",
    "    # OK now for the easy part - just copy over all other edges \n",
    "    # Example: if we have edge from node 1 -> node 2 with weight 0.5 \n",
    "    # AND neither node 1 or 2 are target nodes, we just copy it exactly as is\n",
    "\n",
    "    for u, v, data in orig_graph.edges(data=True):\n",
    "        # Skip any edges that touch target nodes - we already dealt with those in part 4\n",
    "        if v not in targets and u not in targets:\n",
    "            # **data is used to unpacks all attributes automatically\n",
    "            # So if our edge had data = {'weight': 0.5, 'color': 'red'}\n",
    "            # This line becomes: newG.add_edge(u, v, weight=0.5, color='red')\n",
    "            newG.add_edge(u, v, **data)\n",
    "\n",
    "    return newG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static elements preparation for the Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_game_elements(graph, entry_node, original_roots):\n",
    "#    \"\"\"\n",
    "#    This function sets up all the elements needed for our game after we've preprocessed our graph.\n",
    "#    IMPORTANT: This function only determines the POSSIBLE PATHS through the graph.\n",
    "#    The actual weights and parallel edges are used later in calculate_payoff_distribution!\n",
    "\n",
    "#    Returns:\n",
    "#    routes: List of all possible paths from entry to target (ignoring parallel edges)\n",
    "#    V: List of all nodes that appear in any route\n",
    "#    as1: List of nodes where defender can place defenses (excludes entry, target, root nodes)\n",
    "#    as2: Same as routes - all possible attack paths \n",
    "#    target_list: Single-item list containing our virtual target node\n",
    "#    node_order: Nodes in V but sorted in topological order (helps with game calculations)\n",
    "#    \"\"\"\n",
    "#    ## Part 1: Find our Target Node - Should be Only One!\n",
    "#    target_list = [n for n,d in graph.out_degree() if d == 0]\n",
    "#    if len(target_list) != 1:\n",
    "#        print(\"WARNING: Expected exactly one target node after contraction. Found:\", target_list)\n",
    "   \n",
    "#    ## Part 2: Get all UNIQUE Possible Attack Routes Through Graph\n",
    "#    # This means finding all possible node sequences like [0->1->2->target]\n",
    "#    # Note: At this stage we don't care about edge weights - those come into play later!\n",
    "\n",
    "#    ## Part 2a: Get Initial Raw Path List, including duplicates from parallel edges\n",
    "#    # Example: If we have two edges between 1->2, we might get:\n",
    "#    #   Path1: [0->1->2->target] (using first 1->2 edge)\n",
    "#    #   Path2: [0->1->2->target] (using second 1->2 edge)\n",
    "#    raw_routes = list(nx.all_simple_paths(graph, entry_node, target_list[0]))\n",
    "\n",
    "#    ## Part 2b: Remove Duplicate Paths\n",
    "#    # Example: The two paths above would consolidate to just:\n",
    "#    #   [0->1->2->target]\n",
    "#    # Why? Because for now we only care about WHICH nodes can be visited,\n",
    "#    # not HOW (i.e., which specific edges with which weights)\n",
    "#    consolidated_routes = []\n",
    "#    seen_paths = set()\n",
    "\n",
    "#    for path in raw_routes:\n",
    "#        path_key = tuple(path)\n",
    "#        if path_key not in seen_paths:\n",
    "#           seen_paths.add(path_key)\n",
    "#           consolidated_routes.append(list(path))\n",
    "\n",
    "#    # routes now contains our final list of unique possible attack paths\n",
    "#    routes = consolidated_routes\n",
    "\n",
    "#    ## Part 3: Create Node Sets We Need for the Game\n",
    "#    # Part 3a: Get all unique nodes (V) that appear in any route\n",
    "#    V = sorted(set(node for path in routes for node in path), key=str)\n",
    "\n",
    "#    # Part 3b: Get nodes in proper order (helps with game calculations later)\n",
    "#    topo_all = list(nx.topological_sort(graph))\n",
    "#    node_order = []\n",
    "#    for n in topo_all:\n",
    "#       if n in V:\n",
    "#          node_order.append(n)\n",
    "   \n",
    "#    ## Part 4: Create Special Node Lists for Game Logic\n",
    "\n",
    "#    # Part 4a: Create as1 which is a list of potential defender check locations\n",
    "#    # We exclude:\n",
    "#    # - The entry node (obvious - it's just virtual)\n",
    "#    # - The target node (game is over if attacker reaches it)\n",
    "#    # - Original root nodes (they're no longer part of the game)\n",
    "#    excluded = {entry_node} | set(target_list) | set(original_roots)\n",
    "\n",
    "#    # as1 is our list of nodes where the defender can check\n",
    "#    as1 = []\n",
    "#    for n in V:\n",
    "#       if n not in excluded:\n",
    "#        as1.append(n)\n",
    "\n",
    "#    # Part 4b: Set up attack paths (as2)\n",
    "#    # These are just our consolidated routes - we don't care here about the weights\n",
    "#    as2 = routes\n",
    "   \n",
    "#    return routes, V, as1, as2, target_list, node_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creates a list of all possible attacker locations (excluding entry and target nodes)\n",
    "# # Assigns equal probability (1/n) to each possible location in a dictionary\n",
    "# # Counts the total number of attack paths\n",
    "\n",
    "# # Returns:\n",
    "# # adv_list: List of nodes where attacker could be\n",
    "# # theta: Dictionary mapping each possible location to its probability (all equal)\n",
    "# # m: Number of attack paths\n",
    "\n",
    "# def setup_game_parameters(V, routes, entry_node, target_list):\n",
    "#     # prepare all the possible locations of attacker (avatars)\n",
    "#     adv_list = [n for n in V if n not in [entry_node] + target_list]\n",
    "#     if len(adv_list) == 0:\n",
    "#         print(\"WARNING: No adversary intermediate locations found. Check graph structure.\")\n",
    "    \n",
    "#     # Create a dictionary that assigns equal probability to each possible attacker location\n",
    "#     theta = {loc: 1/len(adv_list) for loc in adv_list}\n",
    "#     # Number of attack paths\n",
    "#     m = len(routes)\n",
    "#     return adv_list, theta, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate game elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_payoff_distribution(graph, as1, as2, V, adv_list, theta, random_steps_fn, \n",
    "                                 attack_rate, defense_rate, node_order):\n",
    "   \"\"\"\n",
    "   This function calculates probability distributions for where attackers might end up in the graph\n",
    "   for each defender-attacker strategy combination.\n",
    "   \n",
    "   For each check location and attack path pair:\n",
    "   1. Creates vector U to store final probabilities for each node\n",
    "   2. For each possible attacker starting position (avatar):\n",
    "      - If on attack path: Calculates probabilities of reaching each node up to defender's check\n",
    "      - If not on path: Stays at current position with probability 1.0\n",
    "   3. Weights and combines all starting position probabilities\n",
    "   4. Returns smoothed probability distribution\n",
    "\n",
    "   The edge weights in the graph affect movement probabilities calculated by random_steps_fn.\n",
    "\n",
    "   Returns:\n",
    "   payoffs: List of probability distributions, one for each check location + attack path pair\n",
    "   \"\"\"\n",
    "   payoffs = []\n",
    "\n",
    "   ## Part 1: Process Each Defender Check + Attack Path Combination\n",
    "   # For each pair, we calculate:\n",
    "   # 1. Where attackers starting from different positions might end up\n",
    "   # 2. How the defender's check point affects these probabilities\n",
    "   # 3. A final combined probability distribution across all nodes\n",
    "   for check in as1:\n",
    "       for path in as2:\n",
    "           U = np.zeros(len(V))\n",
    "\n",
    "           # print(f\"\\n++++++++++++++++++++++++++++++++\")\n",
    "           # print(f\"attack_rate = {attack_rate}, defense_rate = {defense_rate}\")\n",
    "           # print(f\"--- Starting payoff calc for check = {check}, path = {path} ---\\n\")\n",
    "\n",
    "           ## Part 2: Handle Each Possible Attacker Starting Position\n",
    "           # For each avatar location:\n",
    "           # 1. Create temporary vector L to store probabilities for this starting position\n",
    "           # 2. Calculate probabilities differently if avatar is on/off attack path\n",
    "           # 3. Weight by probability of attacker starting at this position (theta)\n",
    "           # 4. Add weighted probabilities to final vector U\n",
    "           for avatar in adv_list:\n",
    "               L = np.zeros(len(V))\n",
    "\n",
    "               ## Part 2a: Calculate Probabilities When Attacker Starts On Path\n",
    "               # If avatar is on path:\n",
    "               # 1. Get remaining path from avatar's position\n",
    "               # 2. Calculate movement probabilities using edge weights\n",
    "               # 3. Truncate at defender's check point if present\n",
    "               if avatar in path:\n",
    "                   # Extract relevant portion of path from avatar position\n",
    "                   start_idx = path.index(avatar)\n",
    "                   route = path[start_idx:]\n",
    "                   #print(f\"\\nProcessing avatar {avatar}:\")\n",
    "                   #print(f\"Route from avatar: {route}\")\n",
    "                   \n",
    "                   # Get raw movement probabilities\n",
    "                   pdf_d = random_steps_fn(route, attack_rate, defense_rate, graph)\n",
    "                   #print(f\"PDF for entire route: {pdf_d}\")\n",
    "\n",
    "                   ## Part 2b: Adjust Probabilities Based on Defender's Check Point\n",
    "                   # If defender checks on this route:\n",
    "                   # 1. Truncate probabilities at check point (attacker can't go further)\n",
    "                   # 2. Renormalize remaining probabilities to sum to 1\n",
    "                   if check in route:\n",
    "                       check_idx = route.index(check)\n",
    "                       cutPoint = min(check_idx + 1, len(route))\n",
    "                   else:\n",
    "                       cutPoint = len(route)\n",
    "                   #print(f\"Cut point: {cutPoint}\")\n",
    "\n",
    "                   # Take probabilities up to check point and renormalize\n",
    "                   pdf_subset = pdf_d[:cutPoint]\n",
    "                   if np.sum(pdf_subset) < 1e-15:\n",
    "                       payoffDistr = np.zeros(cutPoint)\n",
    "                       payoffDistr[-1] = 1.0\n",
    "                   else:\n",
    "                       payoffDistr = pdf_subset / np.sum(pdf_subset)\n",
    "                   \n",
    "                   #print(f\"PDF subset: {pdf_subset}\")\n",
    "                   #print(f\"Payoff distribution: {payoffDistr}\")\n",
    "\n",
    "                   # Map probabilities from path positions to node indices in V\n",
    "                   route_subset = route[:cutPoint]\n",
    "                   #print(f\"Route subset: {route_subset}\")\n",
    "                   # for idx_node, node in enumerate(route_subset):\n",
    "                   #     L[V.index(node)] = pdf_d[idx_node]\n",
    "\n",
    "                   for idx_node, node in enumerate(route_subset):\n",
    "                       L[V.index(node)] = payoffDistr[idx_node]\n",
    "                   \n",
    "                   # print(\"L distribution for this avatar (BEFORE weighting by Theta):\")\n",
    "                   # for idx_l, val in enumerate(L):\n",
    "                   #     if val > 1e-10:\n",
    "                   #         print(f\"  Node {V[idx_l]} : {val}\")\n",
    "\n",
    "               ## Part 2c: Handle Case Where Attacker Starts Off Path\n",
    "               # If avatar not on path:\n",
    "               # Set probability 1.0 for staying at current position\n",
    "               else:\n",
    "                   L[V.index(avatar)] = 1.0\n",
    "                   # print(f\"\\nProcessing avatar {avatar} (not in path):\")\n",
    "                   # print(f\"L[{avatar}] = 1.0\")\n",
    "\n",
    "               ## Part 2d: Add Weighted Contribution to Final Probabilities\n",
    "               # Weight this starting position's probabilities by theta\n",
    "               # Add to running total in U\n",
    "               #print(f\"\\nTheta[{avatar}] = {theta[avatar]}\")\n",
    "               U += theta[avatar] * L\n",
    "               #print(\"Current U after adding this avatar's contribution:\")\n",
    "               # for idx_u, val in enumerate(U):\n",
    "               #     if val > 1e-10:\n",
    "               #         print(f\"  Node {V[idx_u]} : {val}\")\n",
    "\n",
    "           ## Part 3: Clean Up and Normalize Final Distribution\n",
    "           # Ensure probabilities sum to 1 and handle edge cases\n",
    "           # print(f\"\\n--- Aggregated U for check={check}, path={path} (BEFORE normalization) ---\")\n",
    "           # for idx_u, val in enumerate(U):\n",
    "           #     if val > 1e-10:\n",
    "           #         print(f\"  Node {V[idx_u]} : {val}\")\n",
    "\n",
    "           # Part 3a: Normalize and Handle Edge Cases \n",
    "           # Ensure no zero probabilities and normalize to sum to 1\n",
    "           U_sum = np.sum(U)\n",
    "           if U_sum < 1e-15:\n",
    "               U = np.full_like(U, 1e-7)\n",
    "           else:\n",
    "               U /= U_sum\n",
    "               U = np.where(U < 1e-7, 1e-7, U)\n",
    "           \n",
    "           # Part 3b: Reorder According to Topological Sort\n",
    "           # Ensure nodes are in correct order for game logic\n",
    "           node_positions = [V.index(n) for n in node_order]\n",
    "           U = U[node_positions]\n",
    "\n",
    "           # print(f\"\\n--- Normalized U for check={check}, path={path} ---\")\n",
    "           # for idx_u2, val2 in enumerate(U):\n",
    "           #     if val2 > 1e-10:\n",
    "           #         print(f\"  Node {node_order[idx_u2]} : {val2}\")\n",
    "\n",
    "           # ld = {\n",
    "           #     'dpdf': U,\n",
    "           #     'support': range(1, len(U) + 1),\n",
    "           #     'cdf': np.cumsum(U),\n",
    "           #     'tail': 1 - np.cumsum(U) + U\n",
    "           # }\n",
    "\n",
    "           ## Part 4: Create Smoothed Distribution\n",
    "           # Convert final probabilities into loss distribution object\n",
    "           # print(f\"Pre-lossDistribution U for check={check}, path={path}:\", U)\n",
    "           ld = lossDistribution(U, smoothing=True, bw=0.2)\n",
    "           payoffs.append(ld)\n",
    "\n",
    "   return payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic elements preparation for the Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to Calculate the Pay_Offs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns \"payoffs\":\n",
    "# payoffs = [\n",
    "#     {'dpdf': [0.1, 0.2, 0.7], 'support': [1,2,3], ...},  # for check1 + path1\n",
    "#     {'dpdf': [0.3, 0.5, 0.2], 'support': [1,2,3], ...},  # for check1 + path2\n",
    "#     {'dpdf': [0.4, 0.4, 0.2], 'support': [1,2,3], ...},  # for check2 + path1\n",
    "#     {'dpdf': [0.1, 0.1, 0.8], 'support': [1,2,3], ...}   # for check2 + path2\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at:\n",
    "{'dpdf': [0.1, 0.2, 0.7], 'support': [1,2,3]}  # for check1 + path1\n",
    "\n",
    "This means:\n",
    "\n",
    "When defender checks at location 1, and attacker uses path1:\n",
    "\n",
    "10% chance attacker is at first node (0.1)\n",
    "\n",
    "20% chance attacker is at second node (0.2)\n",
    "\n",
    "70% chance attacker reached the target node! (0.7)\n",
    "\n",
    "Note: Support [1,2,3] are NOT the node number. I think of them as \"steps away from start\" rather than actual node IDs.\n",
    "\n",
    "That's why we take dpdf[-1] for our payoff matrix - it's the probability the attacker successfully reaches the target node under this check+path combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method necessary to calculate Pay offs within"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is mostly useless and can be removed long term. In my current implementation all we care about is the last entry of U = [0.17, 0.10, 0.63, 0.10, 1e-7] which represents the prob. of the attacker to reach the target node.\n",
    "\n",
    "And per one U (Node Check & Attack Path pair), we extract only this one value for the final pay off matrix. \n",
    "lossDistribution() does not add anything of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossDistribution(U, discrete=True, dataType=\"pdf\", smoothing=\"always\", bw=0.2):\n",
    "   \"\"\"\n",
    "   This function converts a probability distribution U into a standardized loss distribution format.\n",
    "   IMPORTANT: This ensures all probability values are non-zero (>1e-7) and properly normalized.\n",
    "   The output format matches the R implementation's lossDistribution() function.\n",
    "\n",
    "   Returns:\n",
    "   Dictionary containing:\n",
    "   - dpdf: The normalized probability distribution\n",
    "   - support: Range of possible outcomes (1 to n)\n",
    "   - cdf: Cumulative distribution function\n",
    "   - tail: Tail probabilities (1 - CDF + PDF)\n",
    "   - range: Min and max of support range\n",
    "   \"\"\"\n",
    "   ## Part 1: Normalize Input Distribution\n",
    "   # Ensure probabilities sum to 1.0\n",
    "   if np.sum(U) != 1:\n",
    "       U = U / np.sum(U)\n",
    "   \n",
    "   # Create working copy\n",
    "   dpdf = U.copy()\n",
    "   \n",
    "   ## Part 2: Apply Smoothing\n",
    "   # Part 2a: Replace zeros with small positive values\n",
    "   dpdf = np.where(dpdf < 1e-7, 1e-7, dpdf)\n",
    "   \n",
    "   # Part 2b: Re-normalize after smoothing\n",
    "   dpdf = dpdf / np.sum(dpdf)\n",
    "   \n",
    "   ## Part 3: Create Return Dictionary with All Required Components\n",
    "   return {\n",
    "       'dpdf': dpdf,                           # Smoothed probability distribution\n",
    "       'support': np.arange(1, len(dpdf) + 1), # Possible outcomes (1 to n)\n",
    "       'cdf': np.cumsum(dpdf),                 # Cumulative probabilities\n",
    "       'tail': 1 - np.cumsum(dpdf) + dpdf,     # Tail probabilities\n",
    "       'range': [1, len(dpdf)]                 # Min and max of support range\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Payoffs for each path/check pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_payoff_distribution(graph, as1, as2, V, adv_list, theta, random_steps_fn, \n",
    "                                  attack_rate, defense_rate, node_order):\n",
    "    \"\"\"\n",
    "    This function calculates payoff distributions for each defender-attacker strategy pair.\n",
    "    IMPORTANT: This is where the actual edge weights and parallel edges come into play!\n",
    "    The probability calculations here determine how likely an attacker is to reach the target.\n",
    "\n",
    "    Returns:\n",
    "    payoffs: List of dictionaries containing probability distributions for each check location and attack path combination\n",
    "    \"\"\"\n",
    "    payoffs = []\n",
    "\n",
    "    ## Part 1: Iterate Through All Defender-Attacker Strategy Pairs\n",
    "    # For each possible check location and attack path, we'll calculate:\n",
    "    # - How likely the attacker is to reach each node\n",
    "    # - Where they might get caught by the defender\n",
    "    for check in as1:\n",
    "        for path in as2:\n",
    "            U = np.zeros(len(V))\n",
    "\n",
    "            # print(f\"\\n++++++++++++++++++++++++++++++++\")\n",
    "            # print(f\"attack_rate = {attack_rate}, defense_rate = {defense_rate}\")\n",
    "            # print(f\"--- Starting payoff calc for check = {check}, path = {path} ---\\n\")\n",
    "\n",
    "            ## Part 2: Calculate Probabilities for Each Possible Attacker Starting Position\n",
    "            # For each possible attacker location (avatar):\n",
    "            # - If they're on the attack path, calculate how far they might get\n",
    "            # - If they're not on the path, they stay put with probability 1.0\n",
    "            for avatar in adv_list:\n",
    "                L = np.zeros(len(V))\n",
    "\n",
    "                ## Part 2a: Handle Attacker On Current Attack Path\n",
    "                if avatar in path:\n",
    "                    # Get subset of path from avatar's position to end\n",
    "                    start_idx = path.index(avatar)\n",
    "                    route = path[start_idx:]\n",
    "                    #print(f\"\\nProcessing avatar {avatar}:\")\n",
    "                    #print(f\"Route from avatar: {route}\")\n",
    "                    \n",
    "                    # Calculate movement probabilities using edge weights\n",
    "                    pdf_d = random_steps_fn(route, attack_rate, defense_rate, graph)\n",
    "                    #print(f\"PDF for entire route: {pdf_d}\")\n",
    "\n",
    "                    ## Part 2b: Handle Defender's Check Point\n",
    "                    # If defender checks somewhere on this route:\n",
    "                    # - Truncate probabilities at check point\n",
    "                    # - Redistribute probabilities up to check point\n",
    "                    if check in route:\n",
    "                        check_idx = route.index(check)\n",
    "                        cutPoint = min(check_idx + 1, len(route))\n",
    "                    else:\n",
    "                        cutPoint = len(route)\n",
    "                    #print(f\"Cut point: {cutPoint}\")\n",
    "\n",
    "                    pdf_subset = pdf_d[:cutPoint]\n",
    "                    if np.sum(pdf_subset) < 1e-15:\n",
    "                        payoffDistr = np.zeros(cutPoint)\n",
    "                        payoffDistr[-1] = 1.0\n",
    "                    else:\n",
    "                        payoffDistr = pdf_subset / np.sum(pdf_subset)\n",
    "                    \n",
    "                    #print(f\"PDF subset: {pdf_subset}\")\n",
    "                    #print(f\"Payoff distribution: {payoffDistr}\")\n",
    "\n",
    "                    # Fill L for each node in route_subset\n",
    "                    route_subset = route[:cutPoint]\n",
    "                    #print(f\"Route subset: {route_subset}\")\n",
    "                    # for idx_node, node in enumerate(route_subset):\n",
    "                    #     L[V.index(node)] = pdf_d[idx_node]\n",
    "\n",
    "                    for idx_node, node in enumerate(route_subset):\n",
    "                        L[V.index(node)] = payoffDistr[idx_node]\n",
    "                    \n",
    "                    # print(\"L distribution for this avatar (BEFORE weighting by Theta):\")\n",
    "                    # for idx_l, val in enumerate(L):\n",
    "                    #     if val > 1e-10:\n",
    "                    #         print(f\"  Node {V[idx_l]} : {val}\")\n",
    "\n",
    "                ## Part 2c: Handle Attacker Not On Current Path\n",
    "                else:\n",
    "                    L[V.index(avatar)] = 1.0\n",
    "                    # print(f\"\\nProcessing avatar {avatar} (not in path):\")\n",
    "                    # print(f\"L[{avatar}] = 1.0\")\n",
    "\n",
    "                ## Part 2d: Weight Probabilities by Initial Position Likelihood\n",
    "                #print(f\"\\nTheta[{avatar}] = {theta[avatar]}\")\n",
    "                U += theta[avatar] * L\n",
    "                #print(\"Current U after adding this avatar's contribution:\")\n",
    "                # for idx_u, val in enumerate(U):\n",
    "                #     if val > 1e-10:\n",
    "                #         print(f\"  Node {V[idx_u]} : {val}\")\n",
    "\n",
    "            ## Part 3: Normalize and Clean Up Final Probabilities\n",
    "            # print(f\"\\n--- Aggregated U for check={check}, path={path} (BEFORE normalization) ---\")\n",
    "            # for idx_u, val in enumerate(U):\n",
    "            #     if val > 1e-10:\n",
    "            #         print(f\"  Node {V[idx_u]} : {val}\")\n",
    "\n",
    "            # Part 3a: Handle Zero-sum Cases and Normalize\n",
    "            U_sum = np.sum(U)\n",
    "            if U_sum < 1e-15:\n",
    "                U = np.full_like(U, 1e-7)\n",
    "            else:\n",
    "                U /= U_sum\n",
    "                U = np.where(U < 1e-7, 1e-7, U)\n",
    "            \n",
    "            # Part 3b: Reorder Nodes According to Topological Order\n",
    "            node_positions = [V.index(n) for n in node_order]\n",
    "            U = U[node_positions]\n",
    "\n",
    "            # print(f\"\\n--- Normalized U for check={check}, path={path} ---\")\n",
    "            # for idx_u2, val2 in enumerate(U):\n",
    "            #     if val2 > 1e-10:\n",
    "            #         print(f\"  Node {node_order[idx_u2]} : {val2}\")\n",
    "\n",
    "            # ld = {\n",
    "            #     'dpdf': U,\n",
    "            #     'support': range(1, len(U) + 1),\n",
    "            #     'cdf': np.cumsum(U),\n",
    "            #     'tail': 1 - np.cumsum(U) + U\n",
    "            # }\n",
    "\n",
    "            ## Part 4: Create Final Loss Distribution\n",
    "            # print(f\"Pre-lossDistribution U for check={check}, path={path}:\", U)\n",
    "            ld = lossDistribution(U, smoothing=True, bw=0.2)\n",
    "            payoffs.append(ld)\n",
    "\n",
    "    return payoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for finding optimal solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method solves a zero-sum game using linear programming. It first creates a proper payoff matrix from the loss distributions, then solves two LPs: one for defender minimizing attacker success probability, and one for attacker maximizing it. Both optimizations should yield the same equilibrium value.\n",
    "\n",
    "- Constructs payoff matrix\n",
    "- Solves LP for defender FIRST (minimizing attacker success)\n",
    "- Then solves LP for attacker (maximizing their success)\n",
    "- Verifies both values match (equilibrium property)\n",
    "\n",
    "The method returns a dictionary: \n",
    "\n",
    "{\n",
    "\n",
    "    'optimal_defense': {3: 0.6, 4: 0.4},  # defend node 3 with 60% probability, node 4 with 40%                     \n",
    "    'attacker_strategy': [0.3, 0.5, 0.2], # use path 1 with 30% probability, path 2 with 50%, etc.\n",
    "    'defender_success': 0.128,           # defender can keep attacker success ≤ 0.128              \n",
    "    'attacker_success': 0.128            # attacker can achieve at least 0.128\n",
    "                                            \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_game(payoffs, as1, as2):\n",
    "    n = len(as1)\n",
    "    m = len(as2)\n",
    "\n",
    "\n",
    "    # # Add debug statements here\n",
    "    # print(\"\\n=== Debug: Strategy Mappings ===\")\n",
    "    # print(\"Defender strategies (as1):\", as1)\n",
    "    # print(\"Attacker paths (as2):\")\n",
    "    # for idx, path in enumerate(as2):\n",
    "    #     print(f\"Path {idx}:\", path)\n",
    "    \n",
    "    # Create payoff matrix\n",
    "    payoff_matrix = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            idx = i*m + j\n",
    "            ld = payoffs[idx]\n",
    "            payoff_matrix[i, j] = ld['dpdf'][-1]\n",
    "\n",
    "\n",
    "    # NEW DEBUG CODE: Print payoff matrix before optimization\n",
    "    print(\"\\n=== Debug: Final Payoff Matrix ===\")\n",
    "    print(f\"Matrix dimensions: {n} x {m}\\n\")\n",
    "    print(\"Payoff Matrix (probability of reaching target):\")\n",
    "    for i in range(n):\n",
    "        row_str = f\"Row {i+1:2d}:\"\n",
    "        for j in range(m):\n",
    "            row_str += f\" {payoff_matrix[i,j]:8.6f}\"\n",
    "        print(row_str)\n",
    "    print(\"\\n=== End Debug: Final Payoff Matrix ===\\n\")\n",
    "    \n",
    "    ### Start Defender's optimization ###\n",
    "    c = np.zeros(n+1)\n",
    "    c[0] = 1.0\n",
    "    \n",
    "    A_ub = np.zeros((m, n+1))\n",
    "    b_ub = np.zeros(m)\n",
    "    for j in range(m):\n",
    "        A_ub[j,0] = -1.0\n",
    "        for i in range(n):\n",
    "            A_ub[j,i+1] = payoff_matrix[i,j]\n",
    "            \n",
    "    A_eq = np.zeros((1, n+1))\n",
    "    A_eq[0,1:] = 1.0\n",
    "    b_eq = np.array([1.0])\n",
    "    \n",
    "    bounds = [(0,None)]*(n+1)\n",
    "    \n",
    "    v_defender = None\n",
    "    v_attacker = None\n",
    "    \n",
    "    # Solve the LP\n",
    "    res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds)\n",
    "    \n",
    "    ### End Defender's optimization ###\n",
    "    if res.success:\n",
    "        # Extract the results for later logging\n",
    "        v_defender = res.x[0]\n",
    "        x_def = res.x[1:]\n",
    "        \n",
    "        ### Start Attacker's optimization ###\n",
    "        c_att = np.zeros(m+1)\n",
    "        c_att[0] = -1.0\n",
    "        \n",
    "        A_ub_att = np.zeros((n, m+1))\n",
    "        b_ub_att = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            A_ub_att[i,0] = 1.0\n",
    "            for j in range(m):\n",
    "                A_ub_att[i,j+1] = -payoff_matrix[i,j]\n",
    "                \n",
    "        A_eq_att = np.zeros((1, m+1))\n",
    "        A_eq_att[0,1:] = 1.0\n",
    "        b_eq_att = np.array([1.0])\n",
    "        \n",
    "        bounds_att = [(0,None)]*(m+1)\n",
    "        res_att = linprog(c_att, A_ub=A_ub_att, b_ub=b_ub_att, \n",
    "                         A_eq=A_eq_att, b_eq=b_eq_att, bounds=bounds_att)\n",
    "        \n",
    "        ### End Attacker's optimization ###\n",
    "        \n",
    "        if res_att.success:\n",
    "            # Extract attacker results for later logging\n",
    "            y_att = res_att.x[1:]\n",
    "            v_attacker = res_att.x[0]   # new - remove the negative sign because c_att[0] = -1.0\n",
    "            \n",
    "            # Now both values are defined, we can check\n",
    "            if abs(v_defender - v_attacker) > 1e-5:\n",
    "                logger.info(\"\\nWarning: Defender and attacker values don't match!\")\n",
    "                logger.info(f\"Defender value: {v_defender:.6f}\")\n",
    "                logger.info(f\"Attacker value: {v_attacker:.6f}\")\n",
    "            \n",
    "            return {\n",
    "                'optimal_defense': dict(zip(as1, x_def)),\n",
    "                'attacker_strategy': y_att,\n",
    "                'defender_success': v_defender,\n",
    "                'attacker_success': v_attacker\n",
    "            }\n",
    "    \n",
    "    logger.info(\"LP optimization failed\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to run the Actual Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Steps:\n",
    "\n",
    "1. Finds entry node in graph\n",
    "2. Generates game elements (routes, nodes, defense locations) using generate_game_elements()\n",
    "3. Sets up game parameters (adversary locations, probabilities) using setup_game_parameters()\n",
    "\n",
    "Then For each attack/defense rate combination:\n",
    "\n",
    "5. Calculates payoff distributions\n",
    "6. Solves game using solve_game()\n",
    "7. Logs results (optimal strategies, success probabilities)\n",
    "\n",
    "Returns:\n",
    "Nothing - this method only logs results to the logger\n",
    "All output goes to log file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_debug_info(graph, stage=\"\"):\n",
    "    print(f\"\\n{stage}:\")\n",
    "    print(\"Nodes:\", list(graph.nodes()))\n",
    "    print(\"Edges with weights:\")\n",
    "    if isinstance(graph, nx.MultiDiGraph):\n",
    "        # For MultiDiGraph, we need to handle multiple edges between same nodes\n",
    "        for u, v, key, data in graph.edges(data=True, keys=True):\n",
    "            weight = data.get('weight', 1)  # default to 1 if no weight\n",
    "            print(f\"{u} -> {v} (key={key}) : {weight}\")\n",
    "    else:\n",
    "        # Original printing for regular DiGraph\n",
    "        for u, v, data in graph.edges(data=True):\n",
    "            weight = data.get('weight', 1)  # default to 1 if no weight\n",
    "            print(f\"{u} -> {v} : {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brute force re-ordering method for Experiment 3 for easier debugging. \n",
    "Useless for other Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_strategies(as1, as2):\n",
    "    # R's order: [5, 15, 6, 8, 10, 7, 11, 9]\n",
    "    r_order = [5, 15, 6, 8, 10, 7, 11, 9]\n",
    "    \n",
    "    # Print debug information\n",
    "    print(\"\\nDebug - Reordering process:\")\n",
    "    print(\"Current as1:\", as1)\n",
    "    print(\"Desired order:\", r_order)\n",
    "    \n",
    "    # Create new ordered list\n",
    "    as1_reordered = []\n",
    "    for node in r_order:\n",
    "        if node in as1:\n",
    "            as1_reordered.append(node)\n",
    "        else:\n",
    "            print(f\"Warning: Node {node} from R order not found in as1\")\n",
    "            \n",
    "    print(\"Reordered as1:\", as1_reordered)\n",
    "    \n",
    "    if len(as1_reordered) != len(as1):\n",
    "        print(\"Warning: Length mismatch after reordering!\")\n",
    "        print(f\"Original length: {len(as1)}, New length: {len(as1_reordered)}\")\n",
    "    \n",
    "    return as1_reordered, as2\n",
    "\n",
    "def reorder_paths(as2):\n",
    "    # Define R's path ordering\n",
    "    r_paths = [\n",
    "        [0, 1, 5, 15, 'c(12,13,14,16)'],\n",
    "        [0, 3, 6, 8, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 3, 6, 8, 'c(12,13,14,16)'],\n",
    "        [0, 3, 8, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 3, 8, 'c(12,13,14,16)'],\n",
    "        [0, 4, 7, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 4, 7, 'c(12,13,14,16)'],\n",
    "        [0, 2, 11, 'c(12,13,14,16)'],\n",
    "        [0, 2, 9, 'c(12,13,14,16)'],\n",
    "        [0, 2, 10, 15, 'c(12,13,14,16)'],\n",
    "        [0, 2, 'c(12,13,14,16)']\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nDebug - Path reordering:\")\n",
    "    print(\"Current paths:\")\n",
    "    for i, path in enumerate(as2):\n",
    "        print(f\"  {i}: {path}\")\n",
    "    \n",
    "    # Create new ordered list\n",
    "    as2_reordered = []\n",
    "    for r_path in r_paths:\n",
    "        path_found = False\n",
    "        for path in as2:\n",
    "            if path == r_path:\n",
    "                as2_reordered.append(path)\n",
    "                path_found = True\n",
    "                break\n",
    "        if not path_found:\n",
    "            print(f\"Warning: Path {r_path} from R order not found in as2\")\n",
    "    \n",
    "    print(\"\\nReordered paths:\")\n",
    "    for i, path in enumerate(as2_reordered):\n",
    "        print(f\"  {i}: {path}\")\n",
    "    \n",
    "    if len(as2_reordered) != len(as2):\n",
    "        print(\"Warning: Length mismatch after reordering paths!\")\n",
    "        print(f\"Original length: {len(as2)}, New length: {len(as2_reordered)}\")\n",
    "    \n",
    "    return as2_reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game(graph, attack_rate_list, defense_rate_list, random_steps_fn):\n",
    "\n",
    "    # Graph pre processing\n",
    "    virtual_entry_node, graph, original_roots = find_and_add_entry_node(graph)\n",
    "    #print_debug_info(graph, \"Before merging targets\")\n",
    "    graph = merge_targets_with_multi_edges(graph)  # Only use this function\n",
    "    print_debug_info(graph, \"After merging targets\")\n",
    "\n",
    "\n",
    "    # Calculate game elements\n",
    "    #routes, V, as1, as2, target_list, node_order = generate_game_elements(graph, virtual_entry_node, original_roots)\n",
    "    routes, V, as1, as2, target_list, node_order, adv_list, theta, m = generate_game_elements(graph, virtual_entry_node, original_roots)\n",
    "\n",
    "    # # Forceful reordering of strategies to be better able to debug \n",
    "    # # Remove later used mainly for experiment 3\n",
    "    # as1, as2 = reorder_strategies(as1, as2)\n",
    "    # as2 = reorder_paths(as2)\n",
    "\n",
    "    # Setup game parameters\n",
    "    #adv_list, theta, m = setup_game_parameters(V, routes, virtual_entry_node, target_list)\n",
    "    \n",
    "    if not defense_rate_list:\n",
    "        defense_rate_list = [0]\n",
    "    if not attack_rate_list:\n",
    "        attack_rate_list = [0]\n",
    "    \n",
    "    for defenseRate in defense_rate_list:\n",
    "        for attackRate in attack_rate_list:\n",
    "            logger.info(\"\\n++++++++++++++++++++++++++++++++\")\n",
    "            logger.info(f\"\\nThe virtual target nodeID is {target_list[0]}\\n\")\n",
    "            logger.info(f\"attack rate =  {attackRate} , defense rate =  {defenseRate} \\n\")\n",
    "            logger.info(\"\\tequilibrium for multiobjective security game (MOSG)\\n\")\n",
    "            \n",
    "\n",
    "            # changing this was important because the function is now called with the graph\n",
    "            payoffs = calculate_payoff_distribution(\n",
    "                graph, as1, as2, V, adv_list, theta, \n",
    "                random_steps_fn,  # Just pass the function directly\n",
    "                attackRate, defenseRate, node_order\n",
    "            )\n",
    "\n",
    "            # debug_payoff_matrix(payoffs, as1, as2)\n",
    "            \n",
    "            eq = solve_game(payoffs, as1, as2)\n",
    "            if eq is not None:\n",
    "                logger.info(\"optimal defense strategy:\")\n",
    "                logger.info(\"         prob.\")\n",
    "                for node, prob in sorted(eq['optimal_defense'].items(), key=lambda x: str(x[0])):\n",
    "                    logger.info(f\"{node} {prob:.6e}\")\n",
    "                \n",
    "                logger.info(\"\\nworst case attack strategies per goal:\")\n",
    "                logger.info(\"          1\")\n",
    "                if 'attacker_strategy' in eq:\n",
    "                    for idx, prob in enumerate(eq['attacker_strategy'], 1):\n",
    "                        logger.info(f\"{idx} {prob:.7f}\")\n",
    "                logger.info(f\"[1] {eq['attacker_success']:.3f}\")\n",
    "                \n",
    "                logger.info(f\"\\nDefender can keep attacker success below: {eq['defender_success']:.3f}\")\n",
    "                logger.info(f\"Attacker can guarantee success probability of: {eq['attacker_success']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to be called in different Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method is supposed to be run in experiment_X.ipynb files. It is not a standalone script.\n",
    "def main():\n",
    "    # Prepare the graph\n",
    "    work_graph = deepcopy(attack_graph)\n",
    "\n",
    "    # Run the game\n",
    "    run_game(work_graph, attack_rate_list=attack_rate_list, defense_rate_list=defense_rate_list, random_steps_fn=random_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Randomsteps method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_steps(route, attack_rate=None, defense_rate=None, graph=None):\n",
    "#    \"\"\"\n",
    "#    This function calculates movement probabilities for an attacker along a given route.\n",
    "#    IMPORTANT: The probabilities depend on edge weights which represent how hard each step is!\n",
    "\n",
    "#    Returns:\n",
    "#    final_pdf: Probability distribution showing likelihood of attacker stopping at each node\n",
    "#    \"\"\"\n",
    "#    #print(\"\\n=== Debug: random_steps function ===\")\n",
    "#    #print(\"Input route:\", route)\n",
    "#    ## Part 1: Calculate Edge Hardness Values\n",
    "\n",
    "#    # This means finding how difficult each edge is to traverse\n",
    "#    # We use edge weights to determine this - higher weight = harder to cross\n",
    "#    hardness = []\n",
    "#    #print(\"\\nCollecting edge probabilities:\")\n",
    "   \n",
    "#    for i in range(len(route) - 1):\n",
    "#        start_node = route[i]\n",
    "#        end_node = route[i + 1]\n",
    "       \n",
    "#        #print(f\"\\nProcessing edge {start_node} -> {end_node}:\")\n",
    "       \n",
    "#        # Get highest edge weight between these nodes\n",
    "#        # Example: If node 1->2 has multiple edges with weights [0.3, 0.7], we use 0.7\n",
    "#        # because that represents the \"hardest\" path between those nodes\n",
    "#        weight = 0.0  # Default weight if no edges found\n",
    "#        for edge in graph[start_node][end_node].values():\n",
    "#            edge_weight = edge.get('weight', 0.0)  # Get weight with 1.0 as default (might be wrong)\n",
    "#            if edge_weight > weight:\n",
    "#                weight = edge_weight\n",
    "#        #print(f\"Selected weight: {weight}\")\n",
    "           \n",
    "#        # Convert weight to probability using exp(-weight)\n",
    "#        # Example: weight of 2.3 becomes probability of exp(-2.3) ≈ 0.1\n",
    "#        hardness.append(np.exp(-weight))\n",
    "#        #print(f\"Converted to hardness: {np.exp(-weight)}\")\n",
    "   \n",
    "#    #print(\"\\nFinal hardness array:\", hardness)\n",
    "   \n",
    "#    ## Part 2: Convert to Working Format\n",
    "#    hardness = np.array(hardness)\n",
    "#    # Transform our list into numpy array for calculations\n",
    "#    #print(\"Hardness as numpy array:\", hardness)\n",
    "   \n",
    "#    ## Part 3: Calculate Movement Probabilities\n",
    "#    # We calculate two things:\n",
    "#    # 1. Probability of reaching each node (accumulating hardness along the way)\n",
    "#    # hardness [0.8,0.6,0.4]\n",
    "#    # gives us prod = [0.8, 0.8*0.6, 0.8*0.6*0.4]\n",
    "#    # prod = [1.0, 0.8, 0.48, 0.192]         \n",
    "#    cumulative_probs = np.concatenate(([1.0], np.cumprod(hardness)))\n",
    "\n",
    "#    # 2. Probability of stopping at each node (based on the next edge's hardness)\n",
    "#    stop_probs = np.concatenate((1 - hardness, [1.0]))\n",
    "   \n",
    "#    #print(\"Cumulative probabilities:\", cumulative_probs)\n",
    "#    #print(\"Stop probabilities:\", stop_probs)\n",
    "   \n",
    "#    ## Part 4: Generate Final Distribution\n",
    "#    # Combine reaching and stopping probabilities\n",
    "#    # Then normalize to get proper probability distribution\n",
    "#    pdf = cumulative_probs * stop_probs\n",
    "#    # print(\"PDF before normalization:\", pdf)\n",
    "#    # Node0: 1.0 * 0.2 = 0.2    (20% chance of stopping at start)\n",
    "#    # Node1: 0.8 * 0.4 = 0.32   (32% chance of stopping at Node1)\n",
    "#    # Node2: 0.48 * 0.6 = 0.288 (28.8% chance of stopping at Node2)\n",
    "#    # Node3: 0.192 * 1.0 = 0.192 (19.2% chance of reaching final node)\n",
    "   \n",
    "#    if pdf.sum() < 1e-15:\n",
    "#        pdf = np.full_like(pdf, 1e-7)\n",
    "#        #print(\"PDF after handling near-zero sum:\", pdf)\n",
    "   \n",
    "#    final_pdf = pdf / pdf.sum()\n",
    "#    #print(\"Final normalized PDF:\", final_pdf)\n",
    "#    #print(\"=== End random_steps debug ===\\n\")\n",
    "   \n",
    "#    return final_pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Movement: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.special import factorial\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from scipy.stats import geom\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "experiment_log_file = 'experiment_3.log'\n",
    "log_path = os.path.join(os.getcwd(), experiment_log_file)\n",
    "\n",
    "if os.path.exists(log_path):\n",
    "    os.remove(log_path)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "handler = logging.FileHandler(log_path, mode='w')\n",
    "handler.setFormatter(logging.Formatter('%(message)s'))\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.info(f'[1] {experiment_log_file}')\n",
    "logger.info(f'[1] \"{datetime.now().strftime(\"%a %b %d %H:%M:%S %Y\")}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run attack_graph_MIR100.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Third Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_rate_list = [0]   \n",
    "defense_rate_list = [0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "DEFAULT_WEIGHT_VALUE = 0  # Can be changed to 1 if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_steps(route, attack_rate=None, defense_rate=None, graph=None):\n",
    "    \"\"\"\n",
    "    Calculates probabilities for attacker movement along route.\n",
    "    Returns probability distribution over possible ending nodes.\n",
    "    \"\"\"\n",
    "    # Calculate hardness values for each edge \n",
    "    hardness = []\n",
    "    min_hardness = []\n",
    "    for i in range(len(route) - 1):\n",
    "        start_node = route[i]\n",
    "        end_node = route[i + 1]\n",
    "        \n",
    "        # Initialize variables for max weight loop\n",
    "        weights = []\n",
    "        # Collect all weights for max\n",
    "        for edge in graph[start_node][end_node].values():\n",
    "            weights.append(edge.get('weight', DEFAULT_WEIGHT_VALUE))\n",
    "        # Get maximum weight\n",
    "        max_weight = max(weights) if weights else DEFAULT_WEIGHT_VALUE\n",
    "        \n",
    "        # Initialize variables for min weight loop\n",
    "        min_weights = []\n",
    "        # Collect all weights for min\n",
    "        for edge in graph[start_node][end_node].values():\n",
    "            min_weights.append(edge.get('weight', DEFAULT_WEIGHT_VALUE))\n",
    "        # Get minimum weight\n",
    "        min_weight = min(min_weights) if min_weights else DEFAULT_WEIGHT_VALUE\n",
    "            \n",
    "        # Convert weights to probabilities\n",
    "        # We could take max_weight or min_weight here\n",
    "        # hardness.append(np.exp(-max_weight))\n",
    "\n",
    "        # Important: We use min_weight here because of the following reason:\n",
    "        # Since the formula to calculate hardness in R is hardness = exp(-weight)\n",
    "        # taking the minimum weight will give us the maximum hardness\n",
    "        # which translates to the path being EASIEST to traverse.\n",
    "        # Yes hardness of 1 means path is trivial, hardness 0 means path is impossible\n",
    "        hardness.append(np.exp(-min_weight))\n",
    "\n",
    "    \n",
    "    # Convert to arrays\n",
    "    hardness = np.array(hardness)\n",
    "\n",
    "    \n",
    "    # Calculate movement probabilities\n",
    "    cumulative_probs = np.concatenate(([1.0], np.cumprod(hardness)))\n",
    "    stop_probs = np.concatenate((1 - hardness, [1.0]))\n",
    "    \n",
    "    # Calculate final probabilities and normalize\n",
    "    pdf = cumulative_probs * stop_probs\n",
    "    if pdf.sum() < 1e-15:\n",
    "        pdf = np.full_like(pdf, 1e-7)\n",
    "    \n",
    "    return pdf / pdf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After merging targets:\n",
      "Nodes: [1, 5, 15, 11, 3, 6, 8, 4, 7, 2, 9, 10, 0, 'c(12,13,14,16)']\n",
      "Edges with weights:\n",
      "1 -> 5 (key=0) : 2.1958405355640576\n",
      "5 -> 15 (key=0) : 2.1958405355640576\n",
      "15 -> c(12,13,14,16) (key=0) : 0.7489220813074156\n",
      "15 -> c(12,13,14,16) (key=1) : 0.7489220813074156\n",
      "15 -> c(12,13,14,16) (key=2) : 0.7489220813074156\n",
      "11 -> c(12,13,14,16) (key=0) : 1.064439873679208\n",
      "11 -> c(12,13,14,16) (key=1) : 0.7489220813074156\n",
      "11 -> c(12,13,14,16) (key=2) : 0.0\n",
      "3 -> 6 (key=0) : 1.064439873679208\n",
      "3 -> 8 (key=0) : 0.7489220813074156\n",
      "6 -> 8 (key=0) : 0.0\n",
      "8 -> c(12,13,14,16) (key=0) : 0.0\n",
      "8 -> c(12,13,14,16) (key=1) : 0.7489220813074156\n",
      "8 -> 10 (key=0) : 0.0\n",
      "4 -> 7 (key=0) : 0.7489220813074156\n",
      "7 -> c(12,13,14,16) (key=0) : 0.7489220813074156\n",
      "7 -> c(12,13,14,16) (key=1) : 0.7489220813074156\n",
      "7 -> 10 (key=0) : 0.7489220813074156\n",
      "2 -> c(12,13,14,16) (key=0) : 1.064439873679208\n",
      "2 -> 9 (key=0) : 0.7489220813074156\n",
      "2 -> 10 (key=0) : 1.064439873679208\n",
      "2 -> 11 (key=0) : 0.7489220813074156\n",
      "9 -> c(12,13,14,16) (key=0) : 1.064439873679208\n",
      "10 -> 15 (key=0) : 0.0\n",
      "0 -> 1 (key=0) : 0\n",
      "0 -> 3 (key=0) : 0\n",
      "0 -> 4 (key=0) : 0\n",
      "0 -> 2 (key=0) : 0\n",
      "\n",
      "Debug - Reordering process:\n",
      "Current as1: [10, 11, 15, 5, 6, 7, 8, 9]\n",
      "Desired order: [5, 15, 6, 8, 10, 7, 11, 9]\n",
      "Reordered as1: [5, 15, 6, 8, 10, 7, 11, 9]\n",
      "\n",
      "Debug - Path reordering:\n",
      "Current paths:\n",
      "  0: [0, 1, 5, 15, 'c(12,13,14,16)']\n",
      "  1: [0, 3, 6, 8, 'c(12,13,14,16)']\n",
      "  2: [0, 3, 6, 8, 10, 15, 'c(12,13,14,16)']\n",
      "  3: [0, 3, 8, 'c(12,13,14,16)']\n",
      "  4: [0, 3, 8, 10, 15, 'c(12,13,14,16)']\n",
      "  5: [0, 4, 7, 'c(12,13,14,16)']\n",
      "  6: [0, 4, 7, 10, 15, 'c(12,13,14,16)']\n",
      "  7: [0, 2, 'c(12,13,14,16)']\n",
      "  8: [0, 2, 9, 'c(12,13,14,16)']\n",
      "  9: [0, 2, 10, 15, 'c(12,13,14,16)']\n",
      "  10: [0, 2, 11, 'c(12,13,14,16)']\n",
      "\n",
      "Reordered paths:\n",
      "  0: [0, 1, 5, 15, 'c(12,13,14,16)']\n",
      "  1: [0, 3, 6, 8, 10, 15, 'c(12,13,14,16)']\n",
      "  2: [0, 3, 6, 8, 'c(12,13,14,16)']\n",
      "  3: [0, 3, 8, 10, 15, 'c(12,13,14,16)']\n",
      "  4: [0, 3, 8, 'c(12,13,14,16)']\n",
      "  5: [0, 4, 7, 10, 15, 'c(12,13,14,16)']\n",
      "  6: [0, 4, 7, 'c(12,13,14,16)']\n",
      "  7: [0, 2, 11, 'c(12,13,14,16)']\n",
      "  8: [0, 2, 9, 'c(12,13,14,16)']\n",
      "  9: [0, 2, 10, 15, 'c(12,13,14,16)']\n",
      "  10: [0, 2, 'c(12,13,14,16)']\n",
      "\n",
      "=== Debug: Final Payoff Matrix ===\n",
      "Matrix dimensions: 8 x 11\n",
      "\n",
      "Payoff Matrix (probability of reaching target):\n",
      "Row  1: 0.039406 0.171217 0.195410 0.136853 0.122740 0.106259 0.058041 0.122740 0.042335 0.092405 0.028743\n",
      "Row  2: 0.000000 0.000000 0.195410 0.000000 0.122740 0.000000 0.058041 0.122740 0.042335 0.000000 0.028743\n",
      "Row  3: 0.044279 0.118219 0.083333 0.136853 0.122740 0.106259 0.058041 0.122740 0.042335 0.092405 0.028743\n",
      "Row  4: 0.044279 0.078813 0.000000 0.078813 0.000000 0.106259 0.058041 0.122740 0.042335 0.092405 0.028743\n",
      "Row  5: 0.044279 0.039406 0.195410 0.039406 0.122740 0.039406 0.058041 0.122740 0.042335 0.039406 0.028743\n",
      "Row  6: 0.044279 0.171217 0.195410 0.136853 0.122740 0.078813 0.000000 0.122740 0.042335 0.092405 0.028743\n",
      "Row  7: 0.044279 0.171217 0.195410 0.136853 0.122740 0.106259 0.058041 0.000000 0.042335 0.092405 0.028743\n",
      "Row  8: 0.044279 0.171217 0.195410 0.136853 0.122740 0.106259 0.058041 0.122740 0.000000 0.092405 0.028743\n",
      "\n",
      "=== End Debug: Final Payoff Matrix ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %run ctr-core_simple.ipynb\n",
    "%run ctr-core_tests.ipynb\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] experiment_3.log\n",
      "[1] \"Sat Jan 11 13:40:33 2025\"\n",
      "\n",
      "++++++++++++++++++++++++++++++++\n",
      "\n",
      "The virtual target nodeID is c(12,13,14,16)\n",
      "\n",
      "attack rate =  0 , defense rate =  0 \n",
      "\n",
      "\tequilibrium for multiobjective security game (MOSG)\n",
      "\n",
      "optimal defense strategy:\n",
      "         prob.\n",
      "10 0.000000e+00\n",
      "11 2.720264e-01\n",
      "15 1.852234e-01\n",
      "5 0.000000e+00\n",
      "6 0.000000e+00\n",
      "7 0.000000e+00\n",
      "8 5.427503e-01\n",
      "9 0.000000e+00\n",
      "\n",
      "worst case attack strategies per goal:\n",
      "          1\n",
      "1 0.0000000\n",
      "2 0.3573620\n",
      "3 0.1441309\n",
      "4 0.0000000\n",
      "5 0.0000000\n",
      "6 0.0000000\n",
      "7 0.0000000\n",
      "8 0.4985072\n",
      "9 0.0000000\n",
      "10 0.0000000\n",
      "11 0.0000000\n",
      "[1] 0.089\n",
      "\n",
      "Defender can keep attacker success below: 0.089\n",
      "Attacker can guarantee success probability of: 0.089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(experiment_log_file, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old more complex random steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (4159263504.py, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 78\u001b[0;36m\u001b[0m\n\u001b[0;31m    #    return final_pdf\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def random_steps(route, attack_rate=None, defense_rate=None, graph=None):\n",
    "#    \"\"\"\n",
    "#    This function calculates movement probabilities for an attacker along a given route.\n",
    "#    IMPORTANT: The probabilities depend on edge weights which represent how hard each step is!\n",
    "\n",
    "#    Returns:\n",
    "#    final_pdf: Probability distribution showing likelihood of attacker stopping at each node\n",
    "#    \"\"\"\n",
    "#    #print(\"\\n=== Debug: random_steps function ===\")\n",
    "#    #print(\"Input route:\", route)\n",
    "#    ## Part 1: Calculate Edge Hardness Values\n",
    "\n",
    "#    # This means finding how difficult each edge is to traverse\n",
    "#    # We use edge weights to determine this - higher weight = harder to cross\n",
    "#    hardness = []\n",
    "#    #print(\"\\nCollecting edge probabilities:\")\n",
    "   \n",
    "#    for i in range(len(route) - 1):\n",
    "#        start_node = route[i]\n",
    "#        end_node = route[i + 1]\n",
    "       \n",
    "#        #print(f\"\\nProcessing edge {start_node} -> {end_node}:\")\n",
    "       \n",
    "#        # Get highest edge weight between these nodes\n",
    "#        # Example: If node 1->2 has multiple edges with weights [0.3, 0.7], we use 0.7\n",
    "#        # because that represents the \"hardest\" path between those nodes\n",
    "#        weight = 0.0  # Default weight if no edges found\n",
    "#        for edge in graph[start_node][end_node].values():\n",
    "#            edge_weight = edge.get('weight', 0.0)  # Get weight with 1.0 as default (might be wrong)\n",
    "#            if edge_weight > weight:\n",
    "#                weight = edge_weight\n",
    "#        #print(f\"Selected weight: {weight}\")\n",
    "           \n",
    "#        # Convert weight to probability using exp(-weight)\n",
    "#        # Example: weight of 2.3 becomes probability of exp(-2.3) ≈ 0.1\n",
    "#        hardness.append(np.exp(-weight))\n",
    "#        #print(f\"Converted to hardness: {np.exp(-weight)}\")\n",
    "   \n",
    "#    #print(\"\\nFinal hardness array:\", hardness)\n",
    "   \n",
    "#    ## Part 2: Convert to Working Format\n",
    "#    hardness = np.array(hardness)\n",
    "#    # Transform our list into numpy array for calculations\n",
    "#    #print(\"Hardness as numpy array:\", hardness)\n",
    "   \n",
    "#    ## Part 3: Calculate Movement Probabilities\n",
    "#    # We calculate two things:\n",
    "#    # 1. Probability of reaching each node (accumulating hardness along the way)\n",
    "#    # hardness [0.8,0.6,0.4]\n",
    "#    # gives us prod = [0.8, 0.8*0.6, 0.8*0.6*0.4]\n",
    "#    # prod = [1.0, 0.8, 0.48, 0.192]         \n",
    "#    cumulative_probs = np.concatenate(([1.0], np.cumprod(hardness)))\n",
    "\n",
    "#    # 2. Probability of stopping at each node (based on the next edge's hardness)\n",
    "#    stop_probs = np.concatenate((1 - hardness, [1.0]))\n",
    "   \n",
    "#    #print(\"Cumulative probabilities:\", cumulative_probs)\n",
    "#    #print(\"Stop probabilities:\", stop_probs)\n",
    "   \n",
    "#    ## Part 4: Generate Final Distribution\n",
    "#    # Combine reaching and stopping probabilities\n",
    "#    # Then normalize to get proper probability distribution\n",
    "#    pdf = cumulative_probs * stop_probs\n",
    "#    # print(\"PDF before normalization:\", pdf)\n",
    "#    # Node0: 1.0 * 0.2 = 0.2    (20% chance of stopping at start)\n",
    "#    # Node1: 0.8 * 0.4 = 0.32   (32% chance of stopping at Node1)\n",
    "#    # Node2: 0.48 * 0.6 = 0.288 (28.8% chance of stopping at Node2)\n",
    "#    # Node3: 0.192 * 1.0 = 0.192 (19.2% chance of reaching final node)\n",
    "   \n",
    "#    if pdf.sum() < 1e-15:\n",
    "#        pdf = np.full_like(pdf, 1e-7)\n",
    "#        #print(\"PDF after handling near-zero sum:\", pdf)\n",
    "   \n",
    "#    final_pdf = pdf / pdf.sum()\n",
    "#    #print(\"Final normalized PDF:\", final_pdf)\n",
    "#    #print(\"=== End random_steps debug ===\\n\")\n",
    "   \n",
    "#    return final_pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

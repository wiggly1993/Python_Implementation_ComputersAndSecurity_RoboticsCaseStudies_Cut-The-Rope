{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a561af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38052a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_log_file = \"experiment_3_H.log\"\n",
    "log_file = open(output_log_file, 'a')\n",
    "sys.stdout = log_file\n",
    "print(output_log_file)\n",
    "print(datetime.now().strftime(\"%a %b %d %H:%M:%S %Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d6bec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_WEIGHT_VALUE = 0  \n",
    "image_mode = False\n",
    "debug_mode = False\n",
    "\n",
    "%run attack_graph_MIR100.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6a9f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_rate_list = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0581fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_steps(route, attack_rate=None, defense_rate=None, graph=None):\n",
    "    \"\"\"\n",
    "    Calculates probabilities for attacker movement along route.\n",
    "    Returns probability distribution over possible ending nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Part 1: Extract hardness values from all edges and append them\n",
    "    # into one numpy array\n",
    "    # Calculate hardness values for each edge \n",
    "    hardness = []\n",
    "    for i in range(len(route) - 1):\n",
    "        start_node = route[i]\n",
    "        end_node = route[i + 1]\n",
    "        \n",
    "        # Initialize variables for max weight loop\n",
    "        weights = []\n",
    "        # Collect all weights for max\n",
    "        for edge in graph[start_node][end_node].values():\n",
    "            weights.append(edge.get('weight', DEFAULT_WEIGHT_VALUE))\n",
    "        # Get maximum weight\n",
    "        max_weight = max(weights) if weights else DEFAULT_WEIGHT_VALUE\n",
    "        \n",
    "        # Initialize variables for min weight loop\n",
    "        min_weights = []\n",
    "        # Collect all weights for min\n",
    "        for edge in graph[start_node][end_node].values():\n",
    "            min_weights.append(edge.get('weight', DEFAULT_WEIGHT_VALUE))\n",
    "        # Get minimum weight\n",
    "        min_weight = min(min_weights) if min_weights else DEFAULT_WEIGHT_VALUE\n",
    "            \n",
    "        # Convert weights to probabilities\n",
    "        # We could take max_weight or min_weight here\n",
    "        # hardness.append(np.exp(-max_weight))\n",
    "\n",
    "        # Important: We use min_weight here because of the following reason:\n",
    "        # Since the formula to calculate hardness in R is hardness = exp(-weight)\n",
    "        # taking the minimum weight will give us the maximum hardness\n",
    "        # which translates to the path being EASIEST to traverse.\n",
    "        # Yes hardness of 1 means path is trivial, hardness 0 means path is impossible\n",
    "        hardness.append(np.exp(-min_weight))\n",
    "\n",
    "    \n",
    "    \n",
    "    hardness = np.array(hardness)\n",
    "\n",
    "    # print(f'Hardness: {hardness}')\n",
    "\n",
    "    \n",
    "    ## Part 2: Based on the extracted hardness values\n",
    "    ## Calculate Movement Probabilities\n",
    "\n",
    "    # We calculate two things:\n",
    "    # 1. Probability of reaching each node (accumulating hardness along the way)\n",
    "    # Example: if hardness = [0.8, 0.6, 0.4]\n",
    "    # Then cumprod gives us: [0.8, 0.8*0.6, 0.8*0.6*0.4]\n",
    "    # Final cumulative_probs = [1.0, 0.8, 0.48, 0.192]\n",
    "    cumulative_probs = np.concatenate(([1.0], np.cumprod(hardness)))\n",
    "\n",
    "    # 2. Probability of stopping at each node (based on the next edge's hardness)\n",
    "    stop_probs = np.concatenate((1 - hardness, [1.0]))\n",
    "\n",
    "    ## Part 3: Generate Final Distribution\n",
    "    # Combine reaching and stopping probabilities to get probability of stopping at each node\n",
    "    # Example calculation with above values:\n",
    "    # Node0: 1.0 * 0.2 = 0.2    (20% chance of stopping at start)\n",
    "    # Node1: 0.8 * 0.4 = 0.32   (32% chance of stopping at Node1)\n",
    "    # Node2: 0.48 * 0.6 = 0.288 (28.8% chance of stopping at Node2)\n",
    "    # Node3: 0.192 * 1.0 = 0.192 (19.2% chance of reaching final node)\n",
    "    pdf = cumulative_probs * stop_probs\n",
    "\n",
    "    # Handle case where probabilities are essentially zero\n",
    "    if pdf.sum() < 1e-15:\n",
    "        pdf = np.full_like(pdf, 1e-7)\n",
    "\n",
    "    # Normalize to ensure probabilities sum to 1\n",
    "    # print(f\"This is the final pdf that is returned in the end: {pdf / pdf.sum()}\")\n",
    "    return pdf / pdf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cb7c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run heuristic_defense.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "016e52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = sys.__stdout__\n",
    "log_file.close()\n",
    "with open(output_log_file, 'r') as f:\n",
    "    print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
